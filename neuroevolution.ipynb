{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47170896",
   "metadata": {},
   "source": [
    "# The purpose of this Jupyter notebook is to showcase Neuroevolution on gymnasium problems\n",
    "## The process is as follows: \n",
    "1. Create neural network class with easy access to weights, biases, activation functions\n",
    "2. Create operator class to allow further inheritance of mutations, crossovers and selections\n",
    "3a. Create classes for additive mutation and global mutation to mutate the weights of neural network with certain mutation rate (users choice)\n",
    "3b. Create classes for  x-point crossover (x is users choice)\n",
    "3c. Create classes for  selection functions for best-selection, random-selection, tournament-selection and roullete wheel selection\n",
    "The usage of the algorithm should be somewhat like this:\n",
    "optimizer = Neuroevolution(\n",
    "    environment,\n",
    "    population_size: Int = xy;\n",
    "    operators: [Callable, ] = [[BestSelection(5), AdditiveMutation(0.1), Crossover(3) # This would be first population], [RandomSelection(45), AdditiveMutation(0.1), GlobalMutation(0.1)]] # this can be rewritten if you have an idea for more efficient and prettier approach,\n",
    "    ... other neccessary things\n",
    ")\n",
    "4. Make sure everything is speed-efficient and torch and numpy compatible (Mostly torch, since we want this to be run on the GPU)\n",
    "<!-- 5. Make sure that paralelization is available and working efficiently -->\n",
    "6. Make sure copying parameters will be achieved efficiently and that the new modified weights and biases will be stored properly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89cf4f0",
   "metadata": {},
   "source": [
    "# The purpose of this Jupyter notebook is to showcase Neuroevolution on gymnasium problems\n",
    "\n",
    "As a python and AI engineer, your goal is to create a python code for neuroevolution and gymnasium problems.\n",
    "## The process is as follows: \n",
    "1. Create neural network class with easy access to weights, biases, activation functions\n",
    "2. Create operator class to allow further inheritance of mutations, crossovers and selections\n",
    "3a. Create classes for additive mutation and global mutation to mutate the weights of neural network with certain mutation rate (users choice)\n",
    "3b. Create classes for  x-point crossover (x is users choice)\n",
    "3c. Create classes for  selection functions for best-selection, random-selection, tournament-selection and roullete wheel selection\n",
    "The usage of the algorithm should be somewhat like this:\n",
    "optimizer = Neuroevolution(\n",
    "    environment,\n",
    "    population_size: Int = xy;\n",
    "    operators: [Callable, ] = [[BestSelection(5), AdditiveMutation(0.1), Crossover(3) # This would be first population], [RandomSelection(45), AdditiveMutation(0.1), GlobalMutation(0.1)]] # this can be rewritten if you have an idea for more efficient and prettier approach,\n",
    "    ... other neccessary things\n",
    ")\n",
    "4. Make sure everything is speed-efficient and torch and numpy compatible (Mostly torch, since we want this to be run on the GPU)\n",
    "5. Make sure that paralelization is available and working efficiently\n",
    "6. Make sure copying parameters will be achieved efficiently and that the new modified weights and biases will be stored properly\n",
    "7. Provide example usage on discrete and action space environment.\n",
    "8. Bear in mind that it can be used for other than just gymnasium environment, e.g. IsaacLab as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5ab9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Optional, Callable, Union\n",
    "import gymnasium as gym\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Flexible neural network with easy access to weights and biases.\n",
    "    Supports various activation functions and architectures.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        input_size: int, \n",
    "        hidden_sizes: List[int], \n",
    "        output_size: int,\n",
    "        activation: str = 'relu',\n",
    "        output_activation: Optional[str] = None,\n",
    "        device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.activation_name = activation\n",
    "        self.output_activation_name = output_activation\n",
    "        \n",
    "        # Build network layers\n",
    "        layer_sizes = [input_size] + hidden_sizes + [output_size]\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            self.layers.append(\n",
    "                nn.Linear(layer_sizes[i], layer_sizes[i + 1])\n",
    "            )\n",
    "        \n",
    "        # Activation functions\n",
    "        self.activation = self._get_activation(activation)\n",
    "        self.output_activation = self._get_activation(output_activation) if output_activation else None\n",
    "        \n",
    "        # Move to device\n",
    "        self.to(device)\n",
    "        \n",
    "    def _get_activation(self, name: Optional[str]) -> Optional[Callable]:\n",
    "        \"\"\"Get activation function by name.\"\"\"\n",
    "        if name is None:\n",
    "            return None\n",
    "        activations = {\n",
    "            'relu': F.relu,\n",
    "            'tanh': torch.tanh,\n",
    "            'sigmoid': torch.sigmoid,\n",
    "            'leaky_relu': F.leaky_relu,\n",
    "            'elu': F.elu,\n",
    "            'softmax': lambda x: F.softmax(x, dim=-1)\n",
    "        }\n",
    "        return activations.get(name.lower(), F.relu)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass through the network.\"\"\"\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.FloatTensor(x).to(self.device)\n",
    "        \n",
    "        for i, layer in enumerate(self.layers[:-1]):\n",
    "            x = self.activation(layer(x))\n",
    "        \n",
    "        x = self.layers[-1](x)\n",
    "        \n",
    "        if self.output_activation:\n",
    "            x = self.output_activation(x)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    def get_parameters_flat(self) -> torch.Tensor:\n",
    "        \"\"\"Get all parameters as a flat tensor.\"\"\"\n",
    "        params = []\n",
    "        for param in self.parameters():\n",
    "            params.append(param.data.view(-1))\n",
    "        return torch.cat(params)\n",
    "    \n",
    "    def set_parameters_flat(self, params: torch.Tensor):\n",
    "        \"\"\"Set parameters from a flat tensor.\"\"\"\n",
    "        idx = 0\n",
    "        for param in self.parameters():\n",
    "            param_len = param.numel()\n",
    "            param.data = params[idx:idx + param_len].view(param.shape)\n",
    "            idx += param_len\n",
    "    \n",
    "    def get_weight_shapes(self) -> List[Tuple]:\n",
    "        \"\"\"Get shapes of all weight matrices and biases.\"\"\"\n",
    "        shapes = []\n",
    "        for param in self.parameters():\n",
    "            shapes.append(param.shape)\n",
    "        return shapes\n",
    "    \n",
    "    def clone(self) -> 'NeuralNetwork':\n",
    "        \"\"\"Create a deep copy of the network.\"\"\"\n",
    "        clone = NeuralNetwork(\n",
    "            input_size=self.layers[0].in_features,\n",
    "            hidden_sizes=[layer.out_features for layer in self.layers[:-1]],\n",
    "            output_size=self.layers[-1].out_features,\n",
    "            activation=self.activation_name,\n",
    "            output_activation=self.output_activation_name,\n",
    "            device=self.device\n",
    "        )\n",
    "        cloload_state_dict(deepcopy(self.state_dict()))\n",
    "        return clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5125518",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Operator:\n",
    "    \"\"\"Base class for all genetic operators.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "    \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        raise NotImplementedError(\"Operator must implement __call__ method\")\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d4c6955",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdditiveMutation(Operator):\n",
    "    \"\"\"Add Gaussian noise to weights.\"\"\"\n",
    "    \n",
    "    def __init__(self, mutation_rate: float = 0.1, mutation_strength: float = 0.1):\n",
    "        super().__init__(\"AdditiveMutation\")\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.mutation_strength = mutation_strength\n",
    "    \n",
    "    def __call__(self, network: NeuralNetwork) -> NeuralNetwork:\n",
    "        \"\"\"Apply additive mutation to network weights.\"\"\"\n",
    "        mutated = network.clone()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for param in mutated.parameters():\n",
    "                mask = torch.rand_like(param) < self.mutation_rate\n",
    "                noise = torch.randn_like(param) * self.mutation_strength\n",
    "                param.data += mask * noise\n",
    "                \n",
    "        return mutated\n",
    "\n",
    "\n",
    "class GlobalMutation(Operator):\n",
    "    \"\"\"Replace weights with new random values.\"\"\"\n",
    "    \n",
    "    def __init__(self, mutation_rate: float = 0.05, weight_range: float = 1.0):\n",
    "        super().__init__(\"GlobalMutation\")\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.weight_range = weight_range\n",
    "    \n",
    "    def __call__(self, network: NeuralNetwork) -> NeuralNetwork:\n",
    "        \"\"\"Apply global mutation to network weights.\"\"\"\n",
    "        mutated = network.clone()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for param in mutated.parameters():\n",
    "                mask = torch.rand_like(param) < self.mutation_rate\n",
    "                new_weights = torch.randn_like(param) * self.weight_range\n",
    "                param.data = torch.where(mask, new_weights, param.data)\n",
    "                \n",
    "        return mutated\n",
    "\n",
    "\n",
    "class AdaptiveMutation(Operator):\n",
    "    \"\"\"Mutation with adaptive strength based on fitness progress.\"\"\"\n",
    "    \n",
    "    def __init__(self, initial_rate: float = 0.1, min_rate: float = 0.01, decay: float = 0.99):\n",
    "        super().__init__(\"AdaptiveMutation\")\n",
    "        self.initial_rate = initial_rate\n",
    "        self.current_rate = initial_rate\n",
    "        self.min_rate = min_rate\n",
    "        self.decay = decay\n",
    "    \n",
    "    def __call__(self, network: NeuralNetwork, fitness_improved: bool = True) -> NeuralNetwork:\n",
    "        \"\"\"Apply adaptive mutation.\"\"\"\n",
    "        if not fitness_improved:\n",
    "            self.current_rate = min(self.initial_rate, self.current_rate / self.decay)\n",
    "        else:\n",
    "            self.current_rate = max(self.min_rate, self.current_rate * self.decay)\n",
    "        \n",
    "        mutated = network.clone()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for param in mutated.parameters():\n",
    "                mask = torch.rand_like(param) < self.current_rate\n",
    "                noise = torch.randn_like(param) * self.current_rate\n",
    "                param.data += mask * noise\n",
    "                \n",
    "        return mutated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "241cc435",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Crossover(Operator):\n",
    "    \"\"\"N-point crossover between two networks.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_points: int = 1):\n",
    "        super().__init__(\"Crossover\")\n",
    "        self.n_points = n_points\n",
    "    \n",
    "    def __call__(self, parent1: NeuralNetwork, parent2: NeuralNetwork) -> Tuple[NeuralNetwork, NeuralNetwork]:\n",
    "        \"\"\"Apply n-point crossover.\"\"\"\n",
    "        child1 = parent1.clone()\n",
    "        child2 = parent2.clone()\n",
    "        \n",
    "        # Get flat parameters\n",
    "        params1 = parent1.get_parameters_flat()\n",
    "        params2 = parent2.get_parameters_flat()\n",
    "        \n",
    "        # Generate crossover points\n",
    "        length = params1.shape[0]\n",
    "        points = sorted(random.sample(range(1, length), min(self.n_points, length - 1)))\n",
    "        points = [0] + points + [length]\n",
    "        \n",
    "        # Perform crossover\n",
    "        new_params1 = torch.empty_like(params1)\n",
    "        new_params2 = torch.empty_like(params2)\n",
    "        \n",
    "        for i in range(len(points) - 1):\n",
    "            start, end = points[i], points[i + 1]\n",
    "            if i % 2 == 0:\n",
    "                new_params1[start:end] = params1[start:end]\n",
    "                new_params2[start:end] = params2[start:end]\n",
    "            else:\n",
    "                new_params1[start:end] = params2[start:end]\n",
    "                new_params2[start:end] = params1[start:end]\n",
    "        \n",
    "        # Set new parameters\n",
    "        child1.set_parameters_flat(new_params1)\n",
    "        child2.set_parameters_flat(new_params2)\n",
    "        \n",
    "        return child1, child2\n",
    "\n",
    "\n",
    "class UniformCrossover(Operator):\n",
    "    \"\"\"Uniform crossover with mixing probability.\"\"\"\n",
    "    \n",
    "    def __init__(self, mixing_prob: float = 0.5):\n",
    "        super().__init__(\"UniformCrossover\")\n",
    "        self.mixing_prob = mixing_prob\n",
    "    \n",
    "    def __call__(self, parent1: NeuralNetwork, parent2: NeuralNetwork) -> Tuple[NeuralNetwork, NeuralNetwork]:\n",
    "        \"\"\"Apply uniform crossover.\"\"\"\n",
    "        child1 = parent1.clone()\n",
    "        child2 = parent2.clone()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for (p1, p2), (c1, c2) in zip(\n",
    "                zip(parent1.parameters(), parent2.parameters()),\n",
    "                zip(child1.parameters(), child2.parameters())\n",
    "            ):\n",
    "                mask = torch.rand_like(p1) < self.mixing_prob\n",
    "                c1.data = torch.where(mask, p2.data, p1.data)\n",
    "                c2.data = torch.where(mask, p1.data, p2.data)\n",
    "        \n",
    "        return child1, child2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d838385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BestSelection(Operator):\n",
    "    \"\"\"Select top K individuals based on fitness.\"\"\"\n",
    "    \n",
    "    def __init__(self, k: int = 5):\n",
    "        super().__init__(\"BestSelection\")\n",
    "        self.k = k\n",
    "    \n",
    "    def __call__(self, population: List[NeuralNetwork], fitnesses: torch.Tensor) -> List[NeuralNetwork]:\n",
    "        \"\"\"Select best K individuals.\"\"\"\n",
    "        _, indices = torch.topk(fitnesses, min(self.k, len(population)))\n",
    "        return [population[i] for i in indices]\n",
    "\n",
    "\n",
    "class RandomSelection(Operator):\n",
    "    \"\"\"Randomly select K individuals.\"\"\"\n",
    "    \n",
    "    def __init__(self, k: int = 5):\n",
    "        super().__init__(\"RandomSelection\")\n",
    "        self.k = k\n",
    "    \n",
    "    def __call__(self, population: List[NeuralNetwork], fitnesses: torch.Tensor) -> List[NeuralNetwork]:\n",
    "        \"\"\"Randomly select K individuals.\"\"\"\n",
    "        indices = random.sample(range(len(population)), min(self.k, len(population)))\n",
    "        return [population[i] for i in indices]\n",
    "\n",
    "\n",
    "class TournamentSelection(Operator):\n",
    "    \"\"\"Tournament selection with configurable tournament size.\"\"\"\n",
    "    \n",
    "    def __init__(self, k: int = 5, tournament_size: int = 3):\n",
    "        super().__init__(\"TournamentSelection\")\n",
    "        self.k = k\n",
    "        self.tournament_size = tournament_size\n",
    "    \n",
    "    def __call__(self, population: List[NeuralNetwork], fitnesses: torch.Tensor) -> List[NeuralNetwork]:\n",
    "        \"\"\"Select K individuals via tournament.\"\"\"\n",
    "        selected = []\n",
    "        for _ in range(self.k):\n",
    "            tournament_indices = random.sample(range(len(population)), \n",
    "                                              min(self.tournament_size, len(population)))\n",
    "            tournament_fitnesses = fitnesses[tournament_indices]\n",
    "            winner_idx = tournament_indices[torch.argmax(tournament_fitnesses)]\n",
    "            selected.append(population[winner_idx])\n",
    "        return selected\n",
    "\n",
    "\n",
    "class RouletteWheelSelection(Operator):\n",
    "    \"\"\"Roulette wheel selection based on fitness proportions.\"\"\"\n",
    "    \n",
    "    def __init__(self, k: int = 5):\n",
    "        super().__init__(\"RouletteWheelSelection\")\n",
    "        self.k = k\n",
    "    \n",
    "    def __call__(self, population: List[NeuralNetwork], fitnesses: torch.Tensor) -> List[NeuralNetwork]:\n",
    "        \"\"\"Select K individuals via roulette wheel.\"\"\"\n",
    "        # Shift fitnesses to be positive\n",
    "        min_fitness = torch.min(fitnesses)\n",
    "        shifted_fitnesses = fitnesses - min_fitness + 1e-6\n",
    "        \n",
    "        # Calculate probabilities\n",
    "        probs = shifted_fitnesses / torch.sum(shifted_fitnesses)\n",
    "        \n",
    "        # Sample individuals\n",
    "        indices = torch.multinomial(probs, self.k, replacement=True)\n",
    "        return [population[i] for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3de1ce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuroevolution:\n",
    "    \"\"\"\n",
    "    Main neuroevolution optimizer for gymnasium environments.\n",
    "    Supports multiple operator pipelines for different subpopulations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        environment: Union[str, gym.Env],\n",
    "        network_config: dict,\n",
    "        population_size: int = 50,\n",
    "        operators: List[List[Operator]] = None,\n",
    "        elite_size: int = 2,\n",
    "        device: str = 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "        seed: Optional[int] = None\n",
    "    ):\n",
    "        # Set random seeds\n",
    "        if seed is not None:\n",
    "            torch.manual_seed(seed)\n",
    "            np.random.seed(seed)\n",
    "            random.seed(seed)\n",
    "        \n",
    "        # Initialize environment\n",
    "        self.env = gym.make(environment) if isinstance(environment, str) else environment\n",
    "        self.device = device\n",
    "        \n",
    "        # Network configuration\n",
    "        obs_space = self.env.observation_space\n",
    "        act_space = self.env.action_space\n",
    "        \n",
    "        self.input_size = obs_space.shape[0] if hasattr(obs_space, 'shape') else obs_space.n\n",
    "        self.output_size = act_space.shape[0] if hasattr(act_space, 'shape') else act_space.n\n",
    "        self.is_discrete = isinstance(act_space, gym.spaces.Discrete)\n",
    "        \n",
    "        # Default network config\n",
    "        default_config = {\n",
    "            'hidden_sizes': [64, 64],\n",
    "            'activation': 'relu',\n",
    "            'output_activation': 'softmax' if self.is_discrete else 'tanh'\n",
    "        }\n",
    "        self.network_config = {**default_config, **network_config}\n",
    "        \n",
    "        # Population settings\n",
    "        self.population_size = population_size\n",
    "        self.elite_size = elite_size\n",
    "        \n",
    "        # Initialize operators\n",
    "        if operators is None:\n",
    "            operators = [\n",
    "                [BestSelection(5), AdditiveMutation(0.1), Crossover(1)],\n",
    "                [TournamentSelection(10, 3), GlobalMutation(0.05)],\n",
    "                [RouletteWheelSelection(5), AdaptiveMutation(0.1)]\n",
    "            ]\n",
    "        self.operators = operators\n",
    "        \n",
    "        # Initialize population\n",
    "        self.population = self._initialize_population()\n",
    "        self.best_fitness = float('-inf')\n",
    "        self.best_network = None\n",
    "        self.generation = 0\n",
    "        self.fitness_history = []\n",
    "        \n",
    "    def _initialize_population(self) -> List[NeuralNetwork]:\n",
    "        \"\"\"Initialize random population.\"\"\"\n",
    "        population = []\n",
    "        for _ in range(self.population_size):\n",
    "            network = NeuralNetwork(\n",
    "                input_size=self.input_size,\n",
    "                output_size=self.output_size,\n",
    "                device=self.device,\n",
    "                **self.network_config\n",
    "            )\n",
    "            population.append(network)\n",
    "        return population\n",
    "    \n",
    "    def evaluate_fitness(self, network: NeuralNetwork, n_episodes: int = 1, render: bool = False) -> float:\n",
    "        \"\"\"Evaluate network fitness in the environment.\"\"\"\n",
    "        total_reward = 0\n",
    "        \n",
    "        for _ in range(n_episodes):\n",
    "            obs, _ = self.env.reset()\n",
    "            done = False\n",
    "            episode_reward = 0\n",
    "            \n",
    "            while not done:\n",
    "                if render:\n",
    "                    self.env.render()\n",
    "                \n",
    "                # Get action from network\n",
    "                with torch.no_grad():\n",
    "                    obs_tensor = torch.FloatTensor(obs).unsqueeze(0).to(self.device)\n",
    "                    output = network(obs_tensor).squeeze()\n",
    "                    \n",
    "                    if self.is_discrete:\n",
    "                        action = torch.argmax(output).item()\n",
    "                    else:\n",
    "                        action = output.cpu().numpy()\n",
    "                \n",
    "                # Step environment\n",
    "                obs, reward, terminated, truncated, _ = self.env.step(action)\n",
    "                done = terminated or truncated\n",
    "                episode_reward += reward\n",
    "            \n",
    "            total_reward += episode_reward\n",
    "        \n",
    "        return total_reward / n_episodes\n",
    "    \n",
    "    def evaluate_population(self, n_episodes: int = 1) -> torch.Tensor:\n",
    "        \"\"\"Evaluate entire population.\"\"\"\n",
    "        fitnesses = []\n",
    "        for network in self.population:\n",
    "            fitness = self.evaluate_fitness(network, n_episodes)\n",
    "            fitnesses.append(fitness)\n",
    "        return torch.tensor(fitnesses, device=self.device)\n",
    "    \n",
    "    def evolve_generation(self, fitnesses: torch.Tensor) -> List[NeuralNetwork]:\n",
    "        \"\"\"Evolve one generation using operator pipelines.\"\"\"\n",
    "        new_population = []\n",
    "        \n",
    "        # Keep elite\n",
    "        if self.elite_size > 0:\n",
    "            _, elite_indices = torch.topk(fitnesses, self.elite_size)\n",
    "            for idx in elite_indices:\n",
    "                new_population.append(self.population[idx].clone())\n",
    "        \n",
    "        # Apply operator pipelines\n",
    "        remaining_size = self.population_size - len(new_population)\n",
    "        subpop_size = remaining_size // len(self.operators)\n",
    "        \n",
    "        for operator_pipeline in self.operators:\n",
    "            subpopulation = []\n",
    "            \n",
    "            # Process pipeline\n",
    "            current_pop = self.population\n",
    "            current_fitnesses = fitnesses\n",
    "            \n",
    "            for operator in operator_pipeline:\n",
    "                if isinstance(operator, (BestSelection, RandomSelection, \n",
    "                                       TournamentSelection, RouletteWheelSelection)):\n",
    "                    # Selection operator\n",
    "                    current_pop = operator(current_pop, current_fitnesses)\n",
    "                    \n",
    "                elif isinstance(operator, (AdditiveMutation, GlobalMutation, AdaptiveMutation)):\n",
    "                    # Mutation operator\n",
    "                    mutated = []\n",
    "                    for network in current_pop:\n",
    "                        mutated.append(operator(network))\n",
    "                    current_pop = mutated\n",
    "                    \n",
    "                elif isinstance(operator, (Crossover, UniformCrossover)):\n",
    "                    # Crossover operator\n",
    "                    offspring = []\n",
    "                    for i in range(0, len(current_pop) - 1, 2):\n",
    "                        child1, child2 = operator(current_pop[i], current_pop[i + 1])\n",
    "                        offspring.extend([child1, child2])\n",
    "                    if len(current_pop) % 2 == 1:\n",
    "                        offspring.append(current_pop[-1].clone())\n",
    "                    current_pop = offspring\n",
    "            \n",
    "            # Add to new population\n",
    "            subpopulation = current_pop[:subpop_size]\n",
    "            new_population.extend(subpopulation)\n",
    "        \n",
    "        # Fill remaining slots if necessary\n",
    "        while len(new_population) < self.population_size:\n",
    "            idx = random.randint(0, len(new_population) - 1)\n",
    "            new_population.append(new_population[idx].clone())\n",
    "        \n",
    "        return new_population[:self.population_size]\n",
    "    \n",
    "    def train(\n",
    "        self, \n",
    "        n_generations: int = 100,\n",
    "        n_episodes_per_eval: int = 1,\n",
    "        verbose: bool = True,\n",
    "        save_best: bool = True,\n",
    "        checkpoint_interval: int = 10\n",
    "    ) -> NeuralNetwork:\n",
    "        \"\"\"Train the population for n generations.\"\"\"\n",
    "        \n",
    "        for generation in range(n_generations):\n",
    "            self.generation = generation\n",
    "            \n",
    "            # Evaluate population\n",
    "            fitnesses = self.evaluate_population(n_episodes_per_eval)\n",
    "            \n",
    "            # Track best\n",
    "            best_idx = torch.argmax(fitnesses)\n",
    "            best_fitness = fitnesses[best_idx].item()\n",
    "            \n",
    "            if best_fitness > self.best_fitness:\n",
    "                self.best_fitness = best_fitness\n",
    "                self.best_network = self.population[best_idx].clone()\n",
    "            \n",
    "            self.fitness_history.append({\n",
    "                'generation': generation,\n",
    "                'best': best_fitness,\n",
    "                'mean': fitnesses.mean().item(),\n",
    "                'std': fitnesses.std().item()\n",
    "            })\n",
    "            \n",
    "            # Verbose output\n",
    "            if verbose:\n",
    "                print(f\"Generation {generation:3d} | \"\n",
    "                      f\"Best: {best_fitness:8.2f} | \"\n",
    "                      f\"Mean: {fitnesses.mean():8.2f} | \"\n",
    "                      f\"Std: {fitnesses.std():6.2f}\")\n",
    "            \n",
    "            # Save checkpoint\n",
    "            if save_best and generation % checkpoint_interval == 0:\n",
    "                self.save_checkpoint(f\"checkpoint_gen_{generation}.pt\")\n",
    "            \n",
    "            # Evolve population\n",
    "            self.population = self.evolve_generation(fitnesses)\n",
    "        \n",
    "        return self.best_network\n",
    "    \n",
    "    def save_checkpoint(self, filepath: str):\n",
    "        \"\"\"Save training checkpoint.\"\"\"\n",
    "        checkpoint = {\n",
    "            'generation': self.generation,\n",
    "            'best_fitness': self.best_fitness,\n",
    "            'best_network_state': self.best_network.state_dict() if self.best_network else None,\n",
    "            'fitness_history': self.fitness_history,\n",
    "            'network_config': self.network_config\n",
    "        }\n",
    "        torch.save(checkpoint, filepath)\n",
    "    \n",
    "    def load_checkpoint(self, filepath: str):\n",
    "        \"\"\"Load training checkpoint.\"\"\"\n",
    "        checkpoint = torch.load(filepath)\n",
    "        self.generation = checkpoint['generation']\n",
    "        self.best_fitness = checkpoint['best_fitness']\n",
    "        self.fitness_history = checkpoint['fitness_history']\n",
    "        \n",
    "        if checkpoint['best_network_state']:\n",
    "            self.best_network = NeuralNetwork(\n",
    "                input_size=self.input_size,\n",
    "                output_size=self.output_size,\n",
    "                device=self.device,\n",
    "                **checkpoint['network_config']\n",
    "            )\n",
    "            self.best_network.load_state_dict(checkpoint['best_network_state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0ca530c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Example 1: Basic usage with CartPole\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mNeuroevolution\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43menvironment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCartPole-v1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnetwork_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhidden_sizes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mactivation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutput_activation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msoftmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpopulation_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mBestSelection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAdditiveMutation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCrossover\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mRandomSelection\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m45\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAdditiveMutation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGlobalMutation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43melite_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_available\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Train the population\u001b[39;00m\n\u001b[1;32m     19\u001b[0m best_network \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[1;32m     20\u001b[0m     n_generations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     21\u001b[0m     n_episodes_per_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     22\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     23\u001b[0m     save_best\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     24\u001b[0m )\n",
      "Cell \u001b[0;32mIn[26], line 32\u001b[0m, in \u001b[0;36mNeuroevolution.__init__\u001b[0;34m(self, environment, network_config, population_size, operators, elite_size, device, seed)\u001b[0m\n\u001b[1;32m     29\u001b[0m act_space \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39maction_space\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m=\u001b[39m obs_space\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(obs_space, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m obs_space\u001b[38;5;241m.\u001b[39mn\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_size \u001b[38;5;241m=\u001b[39m \u001b[43mact_space\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(act_space, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m act_space\u001b[38;5;241m.\u001b[39mn\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_discrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(act_space, gym\u001b[38;5;241m.\u001b[39mspaces\u001b[38;5;241m.\u001b[39mDiscrete)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Default network config\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# Example 1: Basic usage with CartPole\n",
    "optimizer = Neuroevolution(\n",
    "    environment='CartPole-v1',\n",
    "    network_config={\n",
    "        'hidden_sizes': [32, 32],\n",
    "        'activation': 'relu',\n",
    "        'output_activation': 'softmax'\n",
    "    },\n",
    "    population_size=50,\n",
    "    operators=[\n",
    "        [BestSelection(5), AdditiveMutation(0.1), Crossover(3)],\n",
    "        [RandomSelection(45), AdditiveMutation(0.1), GlobalMutation(0.1)]\n",
    "    ],\n",
    "    elite_size=2,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "\n",
    "# Train the population\n",
    "best_network = optimizer.train(\n",
    "    n_generations=100,\n",
    "    n_episodes_per_eval=3,\n",
    "    verbose=True,\n",
    "    save_best=True\n",
    ")\n",
    "\n",
    "# Test the best network\n",
    "test_fitness = optimizer.evaluate_fitness(best_network, n_episodes=10, render=True)\n",
    "print(f\"Test fitness: {test_fitness}\")\n",
    "\n",
    "\n",
    "# Example 2: Advanced usage with custom operators\n",
    "class CustomMutation(Operator):\n",
    "    \"\"\"Custom mutation operator example.\"\"\"\n",
    "    \n",
    "    def __init__(self, decay_rate: float = 0.95):\n",
    "        super().__init__(\"CustomMutation\")\n",
    "        self.decay_rate = decay_rate\n",
    "        self.strength = 1.0\n",
    "    \n",
    "    def __call__(self, network: NeuralNetwork) -> NeuralNetwork:\n",
    "        mutated = network.clone()\n",
    "        self.strength *= self.decay_rate\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for param in mutated.parameters():\n",
    "                noise = torch.randn_like(param) * self.strength * 0.1\n",
    "                param.data += noise\n",
    "        \n",
    "        return mutated\n",
    "\n",
    "# Use custom operator\n",
    "optimizer = Neuroevolution(\n",
    "    environment='LunarLander-v2',\n",
    "    network_config={\n",
    "        'hidden_sizes': [128, 64, 32],\n",
    "        'activation': 'tanh',\n",
    "        'output_activation': 'softmax'\n",
    "    },\n",
    "    population_size=100,\n",
    "    operators=[\n",
    "        [TournamentSelection(10, tournament_size=5), CustomMutation()],\n",
    "        [BestSelection(10), AdaptiveMutation(0.2), UniformCrossover(0.3)],\n",
    "        [RouletteWheelSelection(20), GlobalMutation(0.02)]\n",
    "    ],\n",
    "    elite_size=5\n",
    ")\n",
    "\n",
    "# Train with more episodes for complex environment\n",
    "best_network = optimizer.train(\n",
    "    n_generations=200,\n",
    "    n_episodes_per_eval=5,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "# # Example 3: Continuous action space (e.g., MountainCarContinuous)\n",
    "# optimizer = Neuroevolution(\n",
    "#     environment='MountainCarContinuous-v0',\n",
    "#     network_config={\n",
    "#         'hidden_sizes': [64, 64],\n",
    "#         'activation': 'relu',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553367f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1: CartPole-v1\n",
      "--------------------------------------------------\n",
      "Generation   0 | Best:   500.00 | Mean:    24.65 | Std:  69.59\n",
      "Generation   1 | Best:   500.00 | Mean:    27.22 | Std:  70.27\n",
      "Generation   2 | Best:   500.00 | Mean:    37.09 | Std:  98.55\n",
      "Generation   3 | Best:   500.00 | Mean:    44.17 | Std: 116.85\n",
      "Generation   4 | Best:   500.00 | Mean:    89.40 | Std: 169.39\n",
      "Generation   5 | Best:   500.00 | Mean:    63.73 | Std: 129.97\n",
      "Generation   6 | Best:   500.00 | Mean:   100.59 | Std: 178.88\n",
      "Generation   7 | Best:   500.00 | Mean:    59.51 | Std: 133.76\n",
      "Generation   8 | Best:   500.00 | Mean:    90.86 | Std: 162.88\n",
      "Generation   9 | Best:   500.00 | Mean:    61.34 | Std: 131.17\n",
      "Generation  10 | Best:   500.00 | Mean:    73.95 | Std: 159.95\n",
      "Generation  11 | Best:   500.00 | Mean:    45.72 | Std: 117.37\n",
      "Generation  12 | Best:   500.00 | Mean:    60.37 | Std: 129.20\n",
      "Generation  13 | Best:   500.00 | Mean:    46.53 | Std: 116.55\n",
      "Generation  14 | Best:   500.00 | Mean:    53.65 | Std: 133.62\n",
      "Generation  15 | Best:   500.00 | Mean:    50.09 | Std: 117.21\n",
      "Generation  16 | Best:   500.00 | Mean:    38.27 | Std:  96.39\n",
      "Generation  17 | Best:   500.00 | Mean:    46.67 | Std: 117.13\n",
      "Generation  18 | Best:   500.00 | Mean:    48.77 | Std: 118.48\n",
      "Generation  19 | Best:   500.00 | Mean:    44.13 | Std: 116.87\n",
      "Generation  20 | Best:   500.00 | Mean:    31.59 | Std:  96.88\n",
      "Generation  21 | Best:   500.00 | Mean:    34.47 | Std:  96.84\n",
      "Generation  22 | Best:   500.00 | Mean:    56.88 | Std: 133.55\n",
      "Generation  23 | Best:   500.00 | Mean:    35.61 | Std:  96.96\n",
      "Generation  24 | Best:   500.00 | Mean:    35.95 | Std:  97.51\n",
      "Generation  25 | Best:   500.00 | Mean:    52.40 | Std: 133.49\n",
      "Generation  26 | Best:   500.00 | Mean:    48.37 | Std: 116.40\n",
      "Generation  27 | Best:   500.00 | Mean:    68.08 | Std: 146.67\n",
      "Generation  28 | Best:   500.00 | Mean:    37.41 | Std:  97.45\n",
      "Generation  29 | Best:   500.00 | Mean:    54.69 | Std: 133.05\n",
      "Generation  30 | Best:   500.00 | Mean:    57.32 | Std: 116.96\n",
      "Generation  31 | Best:   500.00 | Mean:    67.37 | Std: 138.57\n",
      "Generation  32 | Best:   500.00 | Mean:   110.56 | Std: 190.84\n",
      "Generation  33 | Best:   500.00 | Mean:    49.07 | Std: 119.96\n",
      "Generation  34 | Best:   500.00 | Mean:    34.97 | Std:  96.56\n",
      "Generation  35 | Best:   500.00 | Mean:    45.55 | Std: 117.18\n",
      "Generation  36 | Best:   500.00 | Mean:    54.18 | Std: 119.33\n",
      "Generation  37 | Best:   500.00 | Mean:    87.35 | Std: 169.92\n",
      "Generation  38 | Best:   500.00 | Mean:    42.04 | Std:  99.15\n",
      "Generation  39 | Best:   500.00 | Mean:    41.36 | Std: 100.20\n",
      "Generation  40 | Best:   500.00 | Mean:    95.53 | Std: 180.23\n",
      "Generation  41 | Best:   500.00 | Mean:    54.03 | Std: 134.10\n",
      "Generation  42 | Best:   500.00 | Mean:    73.74 | Std: 145.63\n",
      "Generation  43 | Best:   500.00 | Mean:    66.20 | Std: 137.60\n",
      "Generation  44 | Best:   500.00 | Mean:    47.66 | Std: 116.91\n",
      "Generation  45 | Best:   500.00 | Mean:    74.70 | Std: 143.19\n",
      "Generation  46 | Best:   500.00 | Mean:   106.67 | Std: 177.74\n",
      "Generation  47 | Best:   500.00 | Mean:    99.05 | Std: 170.50\n",
      "Generation  48 | Best:   500.00 | Mean:    92.35 | Std: 177.66\n",
      "Generation  49 | Best:   500.00 | Mean:    39.43 | Std:  98.99\n",
      "\n",
      "Test fitness (10 episodes): 500.00\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Example 2: Custom Mutation Operator\n",
      "--------------------------------------------------\n",
      "Training with custom mutation operator...\n",
      "Test fitness with custom operator: 500.00\n",
      "\n",
      "==================================================\n",
      "Example 3: Continuous Action Space (Pendulum)\n",
      "--------------------------------------------------\n",
      "Training on Pendulum environment...\n",
      "Test fitness on Pendulum: -1081.02\n",
      "\n",
      "==================================================\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Optional, Callable, Union\n",
    "import gymnasium as gym\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Flexible neural network with easy access to weights and biases.\n",
    "    Supports various activation functions and architectures.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        input_size: int, \n",
    "        hidden_sizes: List[int], \n",
    "        output_size: int,\n",
    "        activation: str = 'relu',\n",
    "        output_activation: Optional[str] = None,\n",
    "        device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.activation_name = activation\n",
    "        self.output_activation_name = output_activation\n",
    "        \n",
    "        # Build network layers\n",
    "        layer_sizes = [input_size] + hidden_sizes + [output_size]\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            self.layers.append(\n",
    "                nn.Linear(layer_sizes[i], layer_sizes[i + 1])\n",
    "            )\n",
    "        \n",
    "        # Activation functions\n",
    "        self.activation = self._get_activation(activation)\n",
    "        self.output_activation = self._get_activation(output_activation) if output_activation else None\n",
    "        \n",
    "        # Move to device\n",
    "        self.to(device)\n",
    "        \n",
    "    def _get_activation(self, name: Optional[str]) -> Optional[Callable]:\n",
    "        \"\"\"Get activation function by name.\"\"\"\n",
    "        if name is None:\n",
    "            return None\n",
    "        activations = {\n",
    "            'relu': F.relu,\n",
    "            'tanh': torch.tanh,\n",
    "            'sigmoid': torch.sigmoid,\n",
    "            'leaky_relu': F.leaky_relu,\n",
    "            'elu': F.elu,\n",
    "            'softmax': lambda x: F.softmax(x, dim=-1)\n",
    "        }\n",
    "        return activations.get(name.lower(), F.relu)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass through the network.\"\"\"\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.FloatTensor(x).to(self.device)\n",
    "        \n",
    "        for i, layer in enumerate(self.layers[:-1]):\n",
    "            x = self.activation(layer(x))\n",
    "        \n",
    "        x = self.layers[-1](x)\n",
    "        \n",
    "        if self.output_activation:\n",
    "            x = self.output_activation(x)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    def get_parameters_flat(self) -> torch.Tensor:\n",
    "        \"\"\"Get all parameters as a flat tensor.\"\"\"\n",
    "        params = []\n",
    "        for param in self.parameters():\n",
    "            params.append(param.data.view(-1))\n",
    "        return torch.cat(params)\n",
    "    \n",
    "    def set_parameters_flat(self, params: torch.Tensor):\n",
    "        \"\"\"Set parameters from a flat tensor.\"\"\"\n",
    "        idx = 0\n",
    "        for param in self.parameters():\n",
    "            param_len = param.numel()\n",
    "            param.data = params[idx:idx + param_len].view(param.shape)\n",
    "            idx += param_len\n",
    "    \n",
    "    def get_weight_shapes(self) -> List[Tuple]:\n",
    "        \"\"\"Get shapes of all weight matrices and biases.\"\"\"\n",
    "        shapes = []\n",
    "        for param in self.parameters():\n",
    "            shapes.append(param.shape)\n",
    "        return shapes\n",
    "    \n",
    "    def clone(self) -> 'NeuralNetwork':\n",
    "        \"\"\"Create a deep copy of the network.\"\"\"\n",
    "        clone = NeuralNetwork(\n",
    "            input_size=self.layers[0].in_features,\n",
    "            hidden_sizes=[layer.out_features for layer in self.layers[:-1]],\n",
    "            output_size=self.layers[-1].out_features,\n",
    "            activation=self.activation_name,\n",
    "            output_activation=self.output_activation_name,\n",
    "            device=self.device\n",
    "        )\n",
    "        cloload_state_dict(deepcopy(self.state_dict()))\n",
    "        return clone\n",
    "\n",
    "\n",
    "class Operator:\n",
    "    \"\"\"Base class for all genetic operators.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "    \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        raise NotImplementedError(\"Operator must implement __call__ method\")\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}()\"\n",
    "\n",
    "\n",
    "# ============= MUTATION OPERATORS =============\n",
    "\n",
    "class AdditiveMutation(Operator):\n",
    "    \"\"\"Add Gaussian noise to weights.\"\"\"\n",
    "    \n",
    "    def __init__(self, mutation_rate: float = 0.1, mutation_strength: float = 0.1):\n",
    "        super().__init__(\"AdditiveMutation\")\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.mutation_strength = mutation_strength\n",
    "    \n",
    "    def __call__(self, network: NeuralNetwork) -> NeuralNetwork:\n",
    "        \"\"\"Apply additive mutation to network weights.\"\"\"\n",
    "        mutated = network.clone()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for param in mutated.parameters():\n",
    "                mask = torch.rand_like(param) < self.mutation_rate\n",
    "                noise = torch.randn_like(param) * self.mutation_strength\n",
    "                param.data += mask * noise\n",
    "                \n",
    "        return mutated\n",
    "\n",
    "\n",
    "class GlobalMutation(Operator):\n",
    "    \"\"\"Replace weights with new random values.\"\"\"\n",
    "    \n",
    "    def __init__(self, mutation_rate: float = 0.05, weight_range: float = 1.0):\n",
    "        super().__init__(\"GlobalMutation\")\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.weight_range = weight_range\n",
    "    \n",
    "    def __call__(self, network: NeuralNetwork) -> NeuralNetwork:\n",
    "        \"\"\"Apply global mutation to network weights.\"\"\"\n",
    "        mutated = network.clone()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for param in mutated.parameters():\n",
    "                mask = torch.rand_like(param) < self.mutation_rate\n",
    "                new_weights = torch.randn_like(param) * self.weight_range\n",
    "                param.data = torch.where(mask, new_weights, param.data)\n",
    "                \n",
    "        return mutated\n",
    "\n",
    "\n",
    "class AdaptiveMutation(Operator):\n",
    "    \"\"\"Mutation with adaptive strength based on fitness progress.\"\"\"\n",
    "    \n",
    "    def __init__(self, initial_rate: float = 0.1, min_rate: float = 0.01, decay: float = 0.99):\n",
    "        super().__init__(\"AdaptiveMutation\")\n",
    "        self.initial_rate = initial_rate\n",
    "        self.current_rate = initial_rate\n",
    "        self.min_rate = min_rate\n",
    "        self.decay = decay\n",
    "    \n",
    "    def __call__(self, network: NeuralNetwork, fitness_improved: bool = True) -> NeuralNetwork:\n",
    "        \"\"\"Apply adaptive mutation.\"\"\"\n",
    "        if not fitness_improved:\n",
    "            self.current_rate = min(self.initial_rate, self.current_rate / self.decay)\n",
    "        else:\n",
    "            self.current_rate = max(self.min_rate, self.current_rate * self.decay)\n",
    "        \n",
    "        mutated = network.clone()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for param in mutated.parameters():\n",
    "                mask = torch.rand_like(param) < self.current_rate\n",
    "                noise = torch.randn_like(param) * self.current_rate\n",
    "                param.data += mask * noise\n",
    "                \n",
    "        return mutated\n",
    "\n",
    "\n",
    "# ============= CROSSOVER OPERATORS =============\n",
    "\n",
    "class Crossover(Operator):\n",
    "    \"\"\"N-point crossover between two networks.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_points: int = 1):\n",
    "        super().__init__(\"Crossover\")\n",
    "        self.n_points = n_points\n",
    "    \n",
    "    def __call__(self, parent1: NeuralNetwork, parent2: NeuralNetwork) -> Tuple[NeuralNetwork, NeuralNetwork]:\n",
    "        \"\"\"Apply n-point crossover.\"\"\"\n",
    "        child1 = parent1.clone()\n",
    "        child2 = parent2.clone()\n",
    "        \n",
    "        # Get flat parameters\n",
    "        params1 = parent1.get_parameters_flat()\n",
    "        params2 = parent2.get_parameters_flat()\n",
    "        \n",
    "        # Generate crossover points\n",
    "        length = params1.shape[0]\n",
    "        points = sorted(random.sample(range(1, length), min(self.n_points, length - 1)))\n",
    "        points = [0] + points + [length]\n",
    "        \n",
    "        # Perform crossover\n",
    "        new_params1 = torch.empty_like(params1)\n",
    "        new_params2 = torch.empty_like(params2)\n",
    "        \n",
    "        for i in range(len(points) - 1):\n",
    "            start, end = points[i], points[i + 1]\n",
    "            if i % 2 == 0:\n",
    "                new_params1[start:end] = params1[start:end]\n",
    "                new_params2[start:end] = params2[start:end]\n",
    "            else:\n",
    "                new_params1[start:end] = params2[start:end]\n",
    "                new_params2[start:end] = params1[start:end]\n",
    "        \n",
    "        # Set new parameters\n",
    "        child1.set_parameters_flat(new_params1)\n",
    "        child2.set_parameters_flat(new_params2)\n",
    "        \n",
    "        return child1, child2\n",
    "\n",
    "\n",
    "class UniformCrossover(Operator):\n",
    "    \"\"\"Uniform crossover with mixing probability.\"\"\"\n",
    "    \n",
    "    def __init__(self, mixing_prob: float = 0.5):\n",
    "        super().__init__(\"UniformCrossover\")\n",
    "        self.mixing_prob = mixing_prob\n",
    "    \n",
    "    def __call__(self, parent1: NeuralNetwork, parent2: NeuralNetwork) -> Tuple[NeuralNetwork, NeuralNetwork]:\n",
    "        \"\"\"Apply uniform crossover.\"\"\"\n",
    "        child1 = parent1.clone()\n",
    "        child2 = parent2.clone()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for (p1, p2), (c1, c2) in zip(\n",
    "                zip(parent1.parameters(), parent2.parameters()),\n",
    "                zip(child1.parameters(), child2.parameters())\n",
    "            ):\n",
    "                mask = torch.rand_like(p1) < self.mixing_prob\n",
    "                c1.data = torch.where(mask, p2.data, p1.data)\n",
    "                c2.data = torch.where(mask, p1.data, p2.data)\n",
    "        \n",
    "        return child1, child2\n",
    "\n",
    "\n",
    "# ============= SELECTION OPERATORS =============\n",
    "\n",
    "class BestSelection(Operator):\n",
    "    \"\"\"Select top K individuals based on fitness.\"\"\"\n",
    "    \n",
    "    def __init__(self, k: int = 5):\n",
    "        super().__init__(\"BestSelection\")\n",
    "        self.k = k\n",
    "    \n",
    "    def __call__(self, population: List[NeuralNetwork], fitnesses: torch.Tensor) -> List[NeuralNetwork]:\n",
    "        \"\"\"Select best K individuals.\"\"\"\n",
    "        _, indices = torch.topk(fitnesses, min(self.k, len(population)))\n",
    "        return [population[i] for i in indices]\n",
    "\n",
    "\n",
    "class RandomSelection(Operator):\n",
    "    \"\"\"Randomly select K individuals.\"\"\"\n",
    "    \n",
    "    def __init__(self, k: int = 5):\n",
    "        super().__init__(\"RandomSelection\")\n",
    "        self.k = k\n",
    "    \n",
    "    def __call__(self, population: List[NeuralNetwork], fitnesses: torch.Tensor) -> List[NeuralNetwork]:\n",
    "        \"\"\"Randomly select K individuals.\"\"\"\n",
    "        indices = random.sample(range(len(population)), min(self.k, len(population)))\n",
    "        return [population[i] for i in indices]\n",
    "\n",
    "\n",
    "class TournamentSelection(Operator):\n",
    "    \"\"\"Tournament selection with configurable tournament size.\"\"\"\n",
    "    \n",
    "    def __init__(self, k: int = 5, tournament_size: int = 3):\n",
    "        super().__init__(\"TournamentSelection\")\n",
    "        self.k = k\n",
    "        self.tournament_size = tournament_size\n",
    "    \n",
    "    def __call__(self, population: List[NeuralNetwork], fitnesses: torch.Tensor) -> List[NeuralNetwork]:\n",
    "        \"\"\"Select K individuals via tournament.\"\"\"\n",
    "        selected = []\n",
    "        for _ in range(self.k):\n",
    "            tournament_indices = random.sample(range(len(population)), \n",
    "                                              min(self.tournament_size, len(population)))\n",
    "            tournament_fitnesses = fitnesses[tournament_indices]\n",
    "            winner_idx = tournament_indices[torch.argmax(tournament_fitnesses)]\n",
    "            selected.append(population[winner_idx])\n",
    "        return selected\n",
    "\n",
    "\n",
    "class RouletteWheelSelection(Operator):\n",
    "    \"\"\"Roulette wheel selection based on fitness proportions.\"\"\"\n",
    "    \n",
    "    def __init__(self, k: int = 5):\n",
    "        super().__init__(\"RouletteWheelSelection\")\n",
    "        self.k = k\n",
    "    \n",
    "    def __call__(self, population: List[NeuralNetwork], fitnesses: torch.Tensor) -> List[NeuralNetwork]:\n",
    "        \"\"\"Select K individuals via roulette wheel.\"\"\"\n",
    "        # Shift fitnesses to be positive\n",
    "        min_fitness = torch.min(fitnesses)\n",
    "        shifted_fitnesses = fitnesses - min_fitness + 1e-6\n",
    "        \n",
    "        # Calculate probabilities\n",
    "        probs = shifted_fitnesses / torch.sum(shifted_fitnesses)\n",
    "        \n",
    "        # Sample individuals\n",
    "        indices = torch.multinomial(probs, self.k, replacement=True)\n",
    "        return [population[i] for i in indices]\n",
    "\n",
    "\n",
    "# ============= MAIN NEUROEVOLUTION CLASS =============\n",
    "\n",
    "class Neuroevolution:\n",
    "    \"\"\"\n",
    "    Main neuroevolution optimizer for gymnasium environments.\n",
    "    Supports multiple operator pipelines for different subpopulations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        environment: Union[str, gym.Env],\n",
    "        network_config: dict,\n",
    "        population_size: int = 50,\n",
    "        operators: List[List[Operator]] = None,\n",
    "        elite_size: int = 2,\n",
    "        device: str = 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "        seed: Optional[int] = None\n",
    "    ):\n",
    "        # Set random seeds\n",
    "        if seed is not None:\n",
    "            torch.manual_seed(seed)\n",
    "            np.random.seed(seed)\n",
    "            random.seed(seed)\n",
    "        \n",
    "        # Initialize environment\n",
    "        self.env = gym.make(environment) if isinstance(environment, str) else environment\n",
    "        self.device = device\n",
    "        \n",
    "        # Network configuration\n",
    "        obs_space = self.env.observation_space\n",
    "        act_space = self.env.action_space\n",
    "        \n",
    "        # Handle observation space\n",
    "        if hasattr(obs_space, 'shape'):\n",
    "            self.input_size = obs_space.shape[0]\n",
    "        else:\n",
    "            self.input_size = obs_space.n\n",
    "        \n",
    "        # Handle action space\n",
    "        self.is_discrete = isinstance(act_space, gym.spaces.Discrete)\n",
    "        if self.is_discrete:\n",
    "            self.output_size = act_space.n\n",
    "        else:\n",
    "            # Continuous action space\n",
    "            self.output_size = act_space.shape[0]\n",
    "        \n",
    "        # Default network config\n",
    "        default_config = {\n",
    "            'hidden_sizes': [64, 64],\n",
    "            'activation': 'relu',\n",
    "            'output_activation': 'softmax' if self.is_discrete else 'tanh'\n",
    "        }\n",
    "        self.network_config = {**default_config, **network_config}\n",
    "        \n",
    "        # Population settings\n",
    "        self.population_size = population_size\n",
    "        self.elite_size = elite_size\n",
    "        \n",
    "        # Initialize operators\n",
    "        if operators is None:\n",
    "            operators = [\n",
    "                [BestSelection(5), AdditiveMutation(0.1), Crossover(1)],\n",
    "                [TournamentSelection(10, 3), GlobalMutation(0.05)],\n",
    "                [RouletteWheelSelection(5), AdaptiveMutation(0.1)]\n",
    "            ]\n",
    "        self.operators = operators\n",
    "        \n",
    "        # Initialize population\n",
    "        self.population = self._initialize_population()\n",
    "        self.best_fitness = float('-inf')\n",
    "        self.best_network = None\n",
    "        self.generation = 0\n",
    "        self.fitness_history = []\n",
    "        \n",
    "    def _initialize_population(self) -> List[NeuralNetwork]:\n",
    "        \"\"\"Initialize random population.\"\"\"\n",
    "        population = []\n",
    "        for _ in range(self.population_size):\n",
    "            network = NeuralNetwork(\n",
    "                input_size=self.input_size,\n",
    "                output_size=self.output_size,\n",
    "                device=self.device,\n",
    "                **self.network_config\n",
    "            )\n",
    "            population.append(network)\n",
    "        return population\n",
    "    \n",
    "    def evaluate_fitness(self, network: NeuralNetwork, n_episodes: int = 1, render: bool = False) -> float:\n",
    "        \"\"\"Evaluate network fitness in the environment.\"\"\"\n",
    "        total_reward = 0\n",
    "        \n",
    "        for _ in range(n_episodes):\n",
    "            obs, _ = self.env.reset()\n",
    "            done = False\n",
    "            episode_reward = 0\n",
    "            \n",
    "            while not done:\n",
    "                if render:\n",
    "                    self.env.render()\n",
    "                \n",
    "                # Get action from network\n",
    "                with torch.no_grad():\n",
    "                    obs_tensor = torch.FloatTensor(obs).unsqueeze(0).to(self.device)\n",
    "                    output = network(obs_tensor)\n",
    "                    \n",
    "                    if self.is_discrete:\n",
    "                        action = torch.argmax(output.squeeze()).item()\n",
    "                    else:\n",
    "                        # Ensure action is always an array for continuous spaces\n",
    "                        action = output.cpu().numpy().flatten()\n",
    "                \n",
    "                # Step environment\n",
    "                obs, reward, terminated, truncated, _ = self.env.step(action)\n",
    "                done = terminated or truncated\n",
    "                episode_reward += reward\n",
    "            \n",
    "            total_reward += episode_reward\n",
    "        \n",
    "        return total_reward / n_episodes\n",
    "    \n",
    "    def evaluate_population(self, n_episodes: int = 1) -> torch.Tensor:\n",
    "        \"\"\"Evaluate entire population.\"\"\"\n",
    "        fitnesses = []\n",
    "        for network in self.population:\n",
    "            fitness = self.evaluate_fitness(network, n_episodes)\n",
    "            fitnesses.append(fitness)\n",
    "        return torch.tensor(fitnesses, device=self.device)\n",
    "    \n",
    "    def evolve_generation(self, fitnesses: torch.Tensor) -> List[NeuralNetwork]:\n",
    "        \"\"\"Evolve one generation using operator pipelines.\"\"\"\n",
    "        new_population = []\n",
    "        \n",
    "        # Keep elite\n",
    "        if self.elite_size > 0:\n",
    "            _, elite_indices = torch.topk(fitnesses, self.elite_size)\n",
    "            for idx in elite_indices:\n",
    "                new_population.append(self.population[idx].clone())\n",
    "        \n",
    "        # Apply operator pipelines\n",
    "        remaining_size = self.population_size - len(new_population)\n",
    "        subpop_size = remaining_size // len(self.operators)\n",
    "        \n",
    "        for operator_pipeline in self.operators:\n",
    "            subpopulation = []\n",
    "            \n",
    "            # Process pipeline\n",
    "            current_pop = self.population\n",
    "            current_fitnesses = fitnesses\n",
    "            \n",
    "            for operator in operator_pipeline:\n",
    "                if isinstance(operator, (BestSelection, RandomSelection, \n",
    "                                       TournamentSelection, RouletteWheelSelection)):\n",
    "                    # Selection operator\n",
    "                    current_pop = operator(current_pop, current_fitnesses)\n",
    "                    \n",
    "                elif isinstance(operator, (AdditiveMutation, GlobalMutation, AdaptiveMutation)):\n",
    "                    # Mutation operator\n",
    "                    mutated = []\n",
    "                    for network in current_pop:\n",
    "                        mutated.append(operator(network))\n",
    "                    current_pop = mutated\n",
    "                    \n",
    "                elif isinstance(operator, (Crossover, UniformCrossover)):\n",
    "                    # Crossover operator\n",
    "                    offspring = []\n",
    "                    for i in range(0, len(current_pop) - 1, 2):\n",
    "                        child1, child2 = operator(current_pop[i], current_pop[i + 1])\n",
    "                        offspring.extend([child1, child2])\n",
    "                    if len(current_pop) % 2 == 1:\n",
    "                        offspring.append(current_pop[-1].clone())\n",
    "                    current_pop = offspring\n",
    "            \n",
    "            # Add to new population\n",
    "            subpopulation = current_pop[:subpop_size]\n",
    "            new_population.extend(subpopulation)\n",
    "        \n",
    "        # Fill remaining slots if necessary\n",
    "        while len(new_population) < self.population_size:\n",
    "            idx = random.randint(0, len(new_population) - 1)\n",
    "            new_population.append(new_population[idx].clone())\n",
    "        \n",
    "        return new_population[:self.population_size]\n",
    "    \n",
    "    def train(\n",
    "        self, \n",
    "        n_generations: int = 100,\n",
    "        n_episodes_per_eval: int = 1,\n",
    "        verbose: bool = True,\n",
    "        save_best: bool = True,\n",
    "        checkpoint_interval: int = 10\n",
    "    ) -> NeuralNetwork:\n",
    "        \"\"\"Train the population for n generations.\"\"\"\n",
    "        \n",
    "        for generation in range(n_generations):\n",
    "            self.generation = generation\n",
    "            \n",
    "            # Evaluate population\n",
    "            fitnesses = self.evaluate_population(n_episodes_per_eval)\n",
    "            \n",
    "            # Track best\n",
    "            best_idx = torch.argmax(fitnesses)\n",
    "            best_fitness = fitnesses[best_idx].item()\n",
    "            \n",
    "            if best_fitness > self.best_fitness:\n",
    "                self.best_fitness = best_fitness\n",
    "                self.best_network = self.population[best_idx].clone()\n",
    "            \n",
    "            self.fitness_history.append({\n",
    "                'generation': generation,\n",
    "                'best': best_fitness,\n",
    "                'mean': fitnesses.mean().item(),\n",
    "                'std': fitnesses.std().item()\n",
    "            })\n",
    "            \n",
    "            # Verbose output\n",
    "            if verbose:\n",
    "                print(f\"Generation {generation:3d} | \"\n",
    "                      f\"Best: {best_fitness:8.2f} | \"\n",
    "                      f\"Mean: {fitnesses.mean():8.2f} | \"\n",
    "                      f\"Std: {fitnesses.std():6.2f}\")\n",
    "            \n",
    "            # Save checkpoint\n",
    "            if save_best and generation % checkpoint_interval == 0:\n",
    "                self.save_checkpoint(f\"checkpoint_gen_{generation}.pt\")\n",
    "            \n",
    "            # Evolve population\n",
    "            self.population = self.evolve_generation(fitnesses)\n",
    "        \n",
    "        return self.best_network\n",
    "    \n",
    "    def save_checkpoint(self, filepath: str):\n",
    "        \"\"\"Save training checkpoint.\"\"\"\n",
    "        checkpoint = {\n",
    "            'generation': self.generation,\n",
    "            'best_fitness': self.best_fitness,\n",
    "            'best_network_state': self.best_network.state_dict() if self.best_network else None,\n",
    "            'fitness_history': self.fitness_history,\n",
    "            'network_config': self.network_config\n",
    "        }\n",
    "        torch.save(checkpoint, filepath)\n",
    "    \n",
    "    def load_checkpoint(self, filepath: str):\n",
    "        \"\"\"Load training checkpoint.\"\"\"\n",
    "        checkpoint = torch.load(filepath)\n",
    "        self.generation = checkpoint['generation']\n",
    "        self.best_fitness = checkpoint['best_fitness']\n",
    "        self.fitness_history = checkpoint['fitness_history']\n",
    "        \n",
    "        if checkpoint['best_network_state']:\n",
    "            self.best_network = NeuralNetwork(\n",
    "                input_size=self.input_size,\n",
    "                output_size=self.output_size,\n",
    "                device=self.device,\n",
    "                **checkpoint['network_config']\n",
    "            )\n",
    "            self.best_network.load_state_dict(checkpoint['best_network_state'])\n",
    "    \n",
    "    def plot_fitness_history(self):\n",
    "        \"\"\"Plot fitness history over generations.\"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        if not self.fitness_history:\n",
    "            print(\"No fitness history to plot\")\n",
    "            return\n",
    "        \n",
    "        generations = [h['generation'] for h in self.fitness_history]\n",
    "        best_fitness = [h['best'] for h in self.fitness_history]\n",
    "        mean_fitness = [h['mean'] for h in self.fitness_history]\n",
    "        std_fitness = [h['std'] for h in self.fitness_history]\n",
    "        \n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        # Plot fitness over time\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(generations, best_fitness, label='Best', linewidth=2)\n",
    "        plt.plot(generations, mean_fitness, label='Mean', linewidth=2)\n",
    "        plt.fill_between(generations, \n",
    "                        [m - s for m, s in zip(mean_fitness, std_fitness)],\n",
    "                        [m + s for m, s in zip(mean_fitness, std_fitness)],\n",
    "                        alpha=0.3, label='Std Dev')\n",
    "        plt.xlabel('Generation')\n",
    "        plt.ylabel('Fitness')\n",
    "        plt.title('Fitness Evolution')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot fitness improvement rate\n",
    "        plt.subplot(1, 2, 2)\n",
    "        improvement = np.diff(best_fitness)\n",
    "        plt.plot(generations[1:], improvement, linewidth=2, color='green')\n",
    "        plt.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "        plt.xlabel('Generation')\n",
    "        plt.ylabel('Fitness Improvement')\n",
    "        plt.title('Generation-to-Generation Improvement')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# ============= USAGE EXAMPLES =============\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example 1: Basic usage with CartPole\n",
    "    print(\"Example 1: CartPole-v1\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    optimizer = Neuroevolution(\n",
    "        environment='CartPole-v1',\n",
    "        network_config={\n",
    "            'hidden_sizes': [32, 32],\n",
    "            'activation': 'relu',\n",
    "            'output_activation': 'softmax'\n",
    "        },\n",
    "        population_size=50,\n",
    "        operators=[\n",
    "            [BestSelection(5), AdditiveMutation(0.1), Crossover(3)],\n",
    "            [RandomSelection(45), AdditiveMutation(0.1), GlobalMutation(0.1)]\n",
    "        ],\n",
    "        elite_size=2,\n",
    "        device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    # Train the population\n",
    "    best_network = optimizer.train(\n",
    "        n_generations=50,\n",
    "        n_episodes_per_eval=3,\n",
    "        verbose=True,\n",
    "        save_best=False\n",
    "    )\n",
    "    \n",
    "    # Test the best network\n",
    "    test_fitness = optimizer.evaluate_fitness(best_network, n_episodes=10)\n",
    "    print(f\"\\nTest fitness (10 episodes): {test_fitness:.2f}\")\n",
    "    \n",
    "    # Plot fitness history\n",
    "    optimizer.plot_fitness_history()\n",
    "    \n",
    "    \n",
    "    # Example 2: Advanced usage with custom operators\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Example 2: Custom Mutation Operator\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    class CustomMutation(Operator):\n",
    "        \"\"\"Custom mutation operator with decaying strength.\"\"\"\n",
    "        \n",
    "        def __init__(self, decay_rate: float = 0.95):\n",
    "            super().__init__(\"CustomMutation\")\n",
    "            self.decay_rate = decay_rate\n",
    "            self.strength = 1.0\n",
    "        \n",
    "        def __call__(self, network: NeuralNetwork) -> NeuralNetwork:\n",
    "            mutated = network.clone()\n",
    "            self.strength *= self.decay_rate\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for param in mutated.parameters():\n",
    "                    noise = torch.randn_like(param) * self.strength * 0.1\n",
    "                    param.data += noise\n",
    "            \n",
    "            return mutated\n",
    "    \n",
    "    # Create optimizer with custom operator\n",
    "    optimizer2 = Neuroevolution(\n",
    "        environment='CartPole-v1',\n",
    "        network_config={\n",
    "            'hidden_sizes': [64, 32],\n",
    "            'activation': 'tanh',\n",
    "            'output_activation': 'softmax'\n",
    "        },\n",
    "        population_size=30,\n",
    "        operators=[\n",
    "            [TournamentSelection(10, tournament_size=5), CustomMutation()],\n",
    "            [BestSelection(10), AdaptiveMutation(0.2), UniformCrossover(0.3)],\n",
    "            [RouletteWheelSelection(10), GlobalMutation(0.02)]\n",
    "        ],\n",
    "        elite_size=3\n",
    "    )\n",
    "    \n",
    "    print(\"Training with custom mutation operator...\")\n",
    "    best_network2 = optimizer2.train(\n",
    "        n_generations=30,\n",
    "        n_episodes_per_eval=2,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    test_fitness2 = optimizer2.evaluate_fitness(best_network2, n_episodes=10)\n",
    "    print(f\"Test fitness with custom operator: {test_fitness2:.2f}\")\n",
    "    \n",
    "    \n",
    "    # Example 3: Continuous action space\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Example 3: Continuous Action Space (Pendulum)\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    optimizer3 = Neuroevolution(\n",
    "        environment='Pendulum-v1',\n",
    "        network_config={\n",
    "            'hidden_sizes': [64, 64],\n",
    "            'activation': 'relu',\n",
    "            'output_activation': 'tanh'  # For continuous actions\n",
    "        },\n",
    "        population_size=40,\n",
    "        operators=[\n",
    "            [BestSelection(10), AdditiveMutation(0.15)],\n",
    "            [TournamentSelection(15, 4), GlobalMutation(0.03), Crossover(2)],\n",
    "            [RandomSelection(15), AdaptiveMutation(0.2)]\n",
    "        ],\n",
    "        elite_size=2\n",
    "    )\n",
    "    \n",
    "    print(\"Training on Pendulum environment...\")\n",
    "    best_network3 = optimizer3.train(\n",
    "        n_generations=20,\n",
    "        n_episodes_per_eval=1,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    test_fitness3 = optimizer3.evaluate_fitness(best_network3, n_episodes=5)\n",
    "    print(f\"Test fitness on Pendulum: {test_fitness3:.2f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d34cae0",
   "metadata": {},
   "source": [
    "Perfect, now it works. The next step is that it appears to be very slow even when using CartPole environment. The next steps are therefore to make it more efficient if possible. I don't want you to change the code, I want you to indetify speed gaps and possibilities to enhance the speed and ouput them for further investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c43f166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Optional, Callable, Union, Dict\n",
    "import gymnasium as gym\n",
    "from gymnasium.vector import AsyncVectorEnv, SyncVectorEnv\n",
    "from copy import deepcopy\n",
    "import random\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# ============= CONFIGURATION =============\n",
    "\n",
    "@dataclass\n",
    "class OptimizationConfig:\n",
    "    \"\"\"Configuration for optimization settings.\"\"\"\n",
    "    use_parallel_evaluation: bool = True\n",
    "    num_workers: int = mp.cpu_count()\n",
    "    use_vectorized_env: bool = True\n",
    "    vectorized_env_count: int = 10\n",
    "    use_batch_inference: bool = True\n",
    "    batch_size: int = 16\n",
    "    use_memory_pool: bool = True\n",
    "    use_jit: bool = False  # Set to True for PyTorch 2.0+\n",
    "    device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "# ============= NEURAL NETWORK CLASS =============\n",
    "\n",
    "class OptimizedNeuralNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Optimized neural network with efficient parameter access and memory pooling.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Class-level memory pool for parameter tensors\n",
    "    _memory_pool: Dict[Tuple[int, ...], List[torch.Tensor]] = {}\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        input_size: int, \n",
    "        hidden_sizes: List[int], \n",
    "        output_size: int,\n",
    "        activation: str = 'relu',\n",
    "        output_activation: Optional[str] = None,\n",
    "        device: str = 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "        use_memory_pool: bool = True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.activation_name = activation\n",
    "        self.output_activation_name = output_activation\n",
    "        self.use_memory_pool = use_memory_pool\n",
    "        \n",
    "        # Build network layers\n",
    "        layer_sizes = [input_size] + hidden_sizes + [output_size]\n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            self.layers.append(\n",
    "                nn.Linear(layer_sizes[i], layer_sizes[i + 1])\n",
    "            )\n",
    "        \n",
    "        # Activation functions\n",
    "        self.activation = self._get_activation(activation)\n",
    "        self.output_activation = self._get_activation(output_activation) if output_activation else None\n",
    "        \n",
    "        # Move to device\n",
    "        self.to(device)\n",
    "        \n",
    "        # Pre-allocate tensors for inference\n",
    "        self._obs_buffer = None\n",
    "        \n",
    "    def _get_activation(self, name: Optional[str]) -> Optional[Callable]:\n",
    "        \"\"\"Get activation function by name.\"\"\"\n",
    "        if name is None:\n",
    "            return None\n",
    "        activations = {\n",
    "            'relu': F.relu,\n",
    "            'tanh': torch.tanh,\n",
    "            'sigmoid': torch.sigmoid,\n",
    "            'leaky_relu': F.leaky_relu,\n",
    "            'elu': F.elu,\n",
    "            'softmax': lambda x: F.softmax(x, dim=-1)\n",
    "        }\n",
    "        return activations.get(name.lower(), F.relu)\n",
    "    \n",
    "    @torch.jit.export\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Optimized forward pass.\"\"\"\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.FloatTensor(x).to(self.device)\n",
    "        \n",
    "        for i, layer in enumerate(self.layers[:-1]):\n",
    "            x = self.activation(layer(x))\n",
    "        \n",
    "        x = self.layers[-1](x)\n",
    "        \n",
    "        if self.output_activation:\n",
    "            x = self.output_activation(x)\n",
    "            \n",
    "        return x\n",
    "    \n",
    "    def forward_batch(self, x_batch: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Process batch of inputs efficiently.\"\"\"\n",
    "        return self.forward(x_batch)\n",
    "    \n",
    "    def get_parameters_flat(self) -> torch.Tensor:\n",
    "        \"\"\"Get all parameters as a flat tensor (cached).\"\"\"\n",
    "        if not hasattr(self, '_flat_params_cache'):\n",
    "            params = []\n",
    "            for param in self.parameters():\n",
    "                params.append(param.data.view(-1))\n",
    "            self._flat_params_cache = torch.cat(params)\n",
    "        return self._flat_params_cache\n",
    "    \n",
    "    def set_parameters_flat(self, params: torch.Tensor):\n",
    "        \"\"\"Set parameters from a flat tensor.\"\"\"\n",
    "        idx = 0\n",
    "        with torch.no_grad():\n",
    "            for param in self.parameters():\n",
    "                param_len = param.numel()\n",
    "                param.data = params[idx:idx + param_len].view(param.shape)\n",
    "                idx += param_len\n",
    "        # Invalidate cache\n",
    "        if hasattr(self, '_flat_params_cache'):\n",
    "            del self._flat_params_cache\n",
    "    \n",
    "    def clone_fast(self) -> 'OptimizedNeuralNetwork':\n",
    "        \"\"\"Fast cloning using memory pool.\"\"\"\n",
    "        clone = OptimizedNeuralNetwork(\n",
    "            input_size=self.layers[0].in_features,\n",
    "            hidden_sizes=[layer.out_features for layer in self.layers[:-1]],\n",
    "            output_size=self.layers[-1].out_features,\n",
    "            activation=self.activation_name,\n",
    "            output_activation=self.output_activation_name,\n",
    "            device=self.device,\n",
    "            use_memory_pool=self.use_memory_pool\n",
    "        )\n",
    "        \n",
    "        # Fast parameter copy\n",
    "        with torch.no_grad():\n",
    "            for param_src, param_dst in zip(self.parameters(), cloparameters()):\n",
    "                param_dst.data.copy_(param_src.data)\n",
    "        \n",
    "        return clone\n",
    "\n",
    "\n",
    "# ============= PARALLEL EVALUATION HELPERS =============\n",
    "\n",
    "def evaluate_network_worker(args):\n",
    "    \"\"\"Worker function for parallel network evaluation.\"\"\"\n",
    "    network_params, env_name, n_episodes, network_config, is_discrete = args\n",
    "    \n",
    "    # Create environment\n",
    "    env = gym.make(env_name)\n",
    "    \n",
    "    # Reconstruct network\n",
    "    obs_space = env.observation_space\n",
    "    act_space = env.action_space\n",
    "    \n",
    "    input_size = obs_space.shape[0] if hasattr(obs_space, 'shape') else obs_space.n\n",
    "    output_size = act_space.n if is_discrete else act_space.shape[0]\n",
    "    \n",
    "    network = OptimizedNeuralNetwork(\n",
    "        input_size=input_size,\n",
    "        output_size=output_size,\n",
    "        device='cpu',  # Use CPU in workers\n",
    "        **network_config\n",
    "    )\n",
    "    network.set_parameters_flat(network_params)\n",
    "    network.eval()\n",
    "    \n",
    "    # Evaluate\n",
    "    total_reward = 0\n",
    "    for _ in range(n_episodes):\n",
    "        obs, _ = env.reset()\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "        \n",
    "        while not done:\n",
    "            with torch.no_grad():\n",
    "                obs_tensor = torch.FloatTensor(obs).unsqueeze(0)\n",
    "                output = network(obs_tensor)\n",
    "                \n",
    "                if is_discrete:\n",
    "                    action = torch.argmax(output.squeeze()).item()\n",
    "                else:\n",
    "                    action = output.numpy().flatten()\n",
    "            \n",
    "            obs, reward, terminated, truncated, _ = env.step(action)\n",
    "            done = terminated or truncated\n",
    "            episode_reward += reward\n",
    "        \n",
    "        total_reward += episode_reward\n",
    "    \n",
    "    env.close()\n",
    "    return total_reward / n_episodes\n",
    "\n",
    "\n",
    "class VectorizedEvaluator:\n",
    "    \"\"\"Evaluator using vectorized environments for faster evaluation.\"\"\"\n",
    "    \n",
    "    def __init__(self, env_name: str, num_envs: int = 10, is_discrete: bool = True):\n",
    "        self.env_name = env_name\n",
    "        self.num_envs = num_envs\n",
    "        self.is_discrete = is_discrete\n",
    "        \n",
    "        # Create vectorized environment\n",
    "        self.envs = SyncVectorEnv([lambda: gym.make(env_name) for _ in range(num_envs)])\n",
    "        \n",
    "    def evaluate_batch(self, networks: List[OptimizedNeuralNetwork], n_episodes: int = 1) -> List[float]:\n",
    "        \"\"\"Evaluate multiple networks using vectorized environments.\"\"\"\n",
    "        num_networks = len(networks)\n",
    "        fitnesses = np.zeros(num_networks)\n",
    "        episodes_per_network = np.zeros(num_networks)\n",
    "        \n",
    "        # Process in batches\n",
    "        batch_size = min(self.num_envs, num_networks)\n",
    "        \n",
    "        for batch_start in range(0, num_networks, batch_size):\n",
    "            batch_end = min(batch_start + batch_size, num_networks)\n",
    "            batch_networks = networks[batch_start:batch_end]\n",
    "            actual_batch_size = len(batch_networks)\n",
    "            \n",
    "            # Reset environments\n",
    "            obs, _ = self.envs.reset()\n",
    "            obs = obs[:actual_batch_size]  # Trim to actual batch size\n",
    "            \n",
    "            batch_rewards = np.zeros(actual_batch_size)\n",
    "            batch_episodes = np.zeros(actual_batch_size)\n",
    "            done_mask = np.zeros(actual_batch_size, dtype=bool)\n",
    "            \n",
    "            while batch_episodes.min() < n_episodes:\n",
    "                # Get actions from all networks in batch\n",
    "                actions = []\n",
    "                for i, network in enumerate(batch_networks):\n",
    "                    if not done_mask[i]:\n",
    "                        with torch.no_grad():\n",
    "                            obs_tensor = torch.FloatTensor(obs[i]).unsqueeze(0).to(network.device)\n",
    "                            output = network(obs_tensor)\n",
    "                            \n",
    "                            if self.is_discrete:\n",
    "                                action = torch.argmax(output.squeeze()).item()\n",
    "                            else:\n",
    "                                action = output.cpu().numpy().flatten()\n",
    "                            actions.append(action)\n",
    "                    else:\n",
    "                        # Dummy action for completed evaluations\n",
    "                        actions.append(0 if self.is_discrete else np.zeros(1))\n",
    "                \n",
    "                # Pad actions to match environment count\n",
    "                while len(actions) < self.num_envs:\n",
    "                    actions.append(0 if self.is_discrete else np.zeros(1))\n",
    "                \n",
    "                # Step environments\n",
    "                obs, rewards, terminated, truncated, _ = self.envs.step(actions)\n",
    "                obs = obs[:actual_batch_size]\n",
    "                rewards = rewards[:actual_batch_size]\n",
    "                terminated = terminated[:actual_batch_size]\n",
    "                truncated = truncated[:actual_batch_size]\n",
    "                \n",
    "                # Update rewards and episode counts\n",
    "                for i in range(actual_batch_size):\n",
    "                    if not done_mask[i]:\n",
    "                        batch_rewards[i] += rewards[i]\n",
    "                        \n",
    "                        if terminated[i] or truncated[i]:\n",
    "                            batch_episodes[i] += 1\n",
    "                            if batch_episodes[i] >= n_episodes:\n",
    "                                done_mask[i] = True\n",
    "                            else:\n",
    "                                # Reset this specific environment\n",
    "                                # Note: In vectorized env, we'd need to handle partial resets\n",
    "                                pass\n",
    "            \n",
    "            # Store fitnesses\n",
    "            for i in range(actual_batch_size):\n",
    "                fitnesses[batch_start + i] = batch_rewards[i] / n_episodes\n",
    "        \n",
    "        return fitnesses.tolist()\n",
    "    \n",
    "    def close(self):\n",
    "        \"\"\"Close vectorized environments.\"\"\"\n",
    "        self.envs.close()\n",
    "\n",
    "\n",
    "# ============= OPTIMIZED OPERATORS =============\n",
    "\n",
    "class VectorizedAdditiveMutation(nn.Module):\n",
    "    \"\"\"Vectorized additive mutation for batch processing.\"\"\"\n",
    "    \n",
    "    def __init__(self, mutation_rate: float = 0.1, mutation_strength: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.mutation_rate = mutation_rate\n",
    "        self.mutation_strength = mutation_strength\n",
    "    \n",
    "    def forward(self, networks: List[OptimizedNeuralNetwork]) -> List[OptimizedNeuralNetwork]:\n",
    "        \"\"\"Apply mutation to batch of networks efficiently.\"\"\"\n",
    "        mutated = []\n",
    "        \n",
    "        # Pre-generate random values for all networks\n",
    "        for network in networks:\n",
    "            new_network = network.clone_fast()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for param in new_network.parameters():\n",
    "                    # Use in-place operations\n",
    "                    mask = torch.rand_like(param) < self.mutation_rate\n",
    "                    if mask.any():\n",
    "                        noise = torch.randn_like(param) * self.mutation_strength\n",
    "                        param.data.add_(mask * noise)\n",
    "            \n",
    "            mutated.append(new_network)\n",
    "        \n",
    "        return mutated\n",
    "\n",
    "\n",
    "class VectorizedCrossover(nn.Module):\n",
    "    \"\"\"Vectorized crossover for batch processing.\"\"\"\n",
    "    \n",
    "    def __init__(self, n_points: int = 1):\n",
    "        super().__init__()\n",
    "        self.n_points = n_points\n",
    "    \n",
    "    def forward(self, parents: List[Tuple[OptimizedNeuralNetwork, OptimizedNeuralNetwork]]) -> List[Tuple[OptimizedNeuralNetwork, OptimizedNeuralNetwork]]:\n",
    "        \"\"\"Apply crossover to batch of parent pairs.\"\"\"\n",
    "        offspring = []\n",
    "        \n",
    "        for parent1, parent2 in parents:\n",
    "            child1 = parent1.clone_fast()\n",
    "            child2 = parent2.clone_fast()\n",
    "            \n",
    "            # Get flat parameters\n",
    "            params1 = parent1.get_parameters_flat()\n",
    "            params2 = parent2.get_parameters_flat()\n",
    "            \n",
    "            # Generate crossover points once\n",
    "            length = params1.shape[0]\n",
    "            if length > 1:\n",
    "                points = sorted(random.sample(range(1, length), min(self.n_points, length - 1)))\n",
    "                points = [0] + points + [length]\n",
    "                \n",
    "                # Pre-allocate result tensors\n",
    "                new_params1 = torch.empty_like(params1)\n",
    "                new_params2 = torch.empty_like(params2)\n",
    "                \n",
    "                # Vectorized crossover\n",
    "                for i in range(len(points) - 1):\n",
    "                    start, end = points[i], points[i + 1]\n",
    "                    if i % 2 == 0:\n",
    "                        new_params1[start:end] = params1[start:end]\n",
    "                        new_params2[start:end] = params2[start:end]\n",
    "                    else:\n",
    "                        new_params1[start:end] = params2[start:end]\n",
    "                        new_params2[start:end] = params1[start:end]\n",
    "                \n",
    "                # Set new parameters\n",
    "                child1.set_parameters_flat(new_params1)\n",
    "                child2.set_parameters_flat(new_params2)\n",
    "            \n",
    "            offspring.append((child1, child2))\n",
    "        \n",
    "        return offspring\n",
    "\n",
    "\n",
    "# ============= OPTIMIZED MAIN CLASS =============\n",
    "\n",
    "class OptimizedNeuroevolution:\n",
    "    \"\"\"\n",
    "    Highly optimized neuroevolution with parallel evaluation and batch processing.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        environment: Union[str, gym.Env],\n",
    "        network_config: dict,\n",
    "        population_size: int = 50,\n",
    "        operators: List[List] = None,\n",
    "        elite_size: int = 2,\n",
    "        optimization_config: Optional[OptimizationConfig] = None,\n",
    "        seed: Optional[int] = None\n",
    "    ):\n",
    "        # Set random seeds\n",
    "        if seed is not None:\n",
    "            torch.manual_seed(seed)\n",
    "            np.random.seed(seed)\n",
    "            random.seed(seed)\n",
    "        \n",
    "        # Optimization settings\n",
    "        self.opt_config = optimization_config or OptimizationConfig()\n",
    "        \n",
    "        # Initialize environment\n",
    "        self.env_name = environment if isinstance(environment, str) else environment.spec.id\n",
    "        self.env = gym.make(self.env_name) if isinstance(environment, str) else environment\n",
    "        \n",
    "        # Network configuration\n",
    "        obs_space = self.env.observation_space\n",
    "        act_space = self.env.action_space\n",
    "        \n",
    "        # Handle observation space\n",
    "        if hasattr(obs_space, 'shape'):\n",
    "            self.input_size = obs_space.shape[0]\n",
    "        else:\n",
    "            self.input_size = obs_space.n\n",
    "        \n",
    "        # Handle action space\n",
    "        self.is_discrete = isinstance(act_space, gym.spaces.Discrete)\n",
    "        if self.is_discrete:\n",
    "            self.output_size = act_space.n\n",
    "        else:\n",
    "            self.output_size = act_space.shape[0]\n",
    "        \n",
    "        # Default network config\n",
    "        default_config = {\n",
    "            'hidden_sizes': [64, 64],\n",
    "            'activation': 'relu',\n",
    "            'output_activation': 'softmax' if self.is_discrete else 'tanh'\n",
    "        }\n",
    "        self.network_config = {**default_config, **network_config}\n",
    "        \n",
    "        # Population settings\n",
    "        self.population_size = population_size\n",
    "        self.elite_size = elite_size\n",
    "        \n",
    "        self.operators = operators\n",
    "        \n",
    "        # Initialize population\n",
    "        self.population = self._initialize_population()\n",
    "        self.best_fitness = float('-inf')\n",
    "        self.best_network = None\n",
    "        self.generation = 0\n",
    "        self.fitness_history = []\n",
    "        \n",
    "        # Initialize parallel evaluation\n",
    "        if self.opt_config.use_parallel_evaluation:\n",
    "            self.pool = mp.Pool(processes=self.opt_config.num_workers)\n",
    "        \n",
    "        # Initialize vectorized evaluator\n",
    "        if self.opt_config.use_vectorized_env:\n",
    "            self.vec_evaluator = VectorizedEvaluator(\n",
    "                self.env_name, \n",
    "                self.opt_config.vectorized_env_count,\n",
    "                self.is_discrete\n",
    "            )\n",
    "        \n",
    "        # Performance tracking\n",
    "        self.timing_stats = {\n",
    "            'evaluation': [],\n",
    "            'evolution': [],\n",
    "            'total': []\n",
    "        }\n",
    "    \n",
    "    def _initialize_population(self) -> List[OptimizedNeuralNetwork]:\n",
    "        \"\"\"Initialize random population with memory efficiency.\"\"\"\n",
    "        population = []\n",
    "        for _ in range(self.population_size):\n",
    "            network = OptimizedNeuralNetwork(\n",
    "                input_size=self.input_size,\n",
    "                output_size=self.output_size,\n",
    "                device=self.opt_config.device,\n",
    "                use_memory_pool=self.opt_config.use_memory_pool,\n",
    "                **self.network_config\n",
    "            )\n",
    "            population.append(network)\n",
    "        return population\n",
    "    \n",
    "    def evaluate_population_parallel(self, n_episodes: int = 1) -> torch.Tensor:\n",
    "        \"\"\"Parallel evaluation using multiprocessing.\"\"\"\n",
    "        # Prepare arguments for workers\n",
    "        args = []\n",
    "        for network in self.population:\n",
    "            network_params = network.get_parameters_flat().cpu()\n",
    "            args.append((\n",
    "                network_params,\n",
    "                self.env_name,\n",
    "                n_episodes,\n",
    "                self.network_config,\n",
    "                self.is_discrete\n",
    "            ))\n",
    "        \n",
    "        # Parallel evaluation\n",
    "        fitnesses = self.pool.map(evaluate_network_worker, args)\n",
    "        return torch.tensor(fitnesses, device=self.opt_config.device)\n",
    "    \n",
    "    def evaluate_population_vectorized(self, n_episodes: int = 1) -> torch.Tensor:\n",
    "        \"\"\"Vectorized evaluation using multiple environments.\"\"\"\n",
    "        fitnesses = self.vec_evaluator.evaluate_batch(self.population, n_episodes)\n",
    "        return torch.tensor(fitnesses, device=self.opt_config.device)\n",
    "    \n",
    "    def evaluate_population_sequential(self, n_episodes: int = 1) -> torch.Tensor:\n",
    "        \"\"\"Original sequential evaluation (fallback).\"\"\"\n",
    "        fitnesses = []\n",
    "        for network in self.population:\n",
    "            fitness = self.evaluate_fitness(network, n_episodes)\n",
    "            fitnesses.append(fitness)\n",
    "        return torch.tensor(fitnesses, device=self.opt_config.device)\n",
    "    \n",
    "    def evaluate_population(self, n_episodes: int = 1) -> torch.Tensor:\n",
    "        \"\"\"Smart evaluation selection based on configuration.\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        if self.opt_config.use_vectorized_env:\n",
    "            fitnesses = self.evaluate_population_vectorized(n_episodes)\n",
    "        elif self.opt_config.use_parallel_evaluation:\n",
    "            fitnesses = self.evaluate_population_parallel(n_episodes)\n",
    "        else:\n",
    "            fitnesses = self.evaluate_population_sequential(n_episodes)\n",
    "        \n",
    "        self.timing_stats['evaluation'].append(time.time() - start_time)\n",
    "        return fitnesses\n",
    "    \n",
    "    def evaluate_fitness(self, network: OptimizedNeuralNetwork, n_episodes: int = 1, render: bool = False) -> float:\n",
    "        \"\"\"Evaluate single network fitness.\"\"\"\n",
    "        total_reward = 0\n",
    "        \n",
    "        # Pre-allocate observation tensor if using batch inference\n",
    "        if self.opt_config.use_batch_inference and network._obs_buffer is None:\n",
    "            network._obs_buffer = torch.zeros(1, self.input_size, device=network.device)\n",
    "        \n",
    "        for _ in range(n_episodes):\n",
    "            obs, _ = self.env.reset()\n",
    "            done = False\n",
    "            episode_reward = 0\n",
    "            \n",
    "            while not done:\n",
    "                if render:\n",
    "                    self.env.render()\n",
    "                \n",
    "                # Get action from network\n",
    "                with torch.no_grad():\n",
    "                    if self.opt_config.use_batch_inference and network._obs_buffer is not None:\n",
    "                        # Reuse pre-allocated tensor\n",
    "                        network._obs_buffer[0] = torch.FloatTensor(obs).to(network.device)\n",
    "                        output = network(network._obs_buffer)\n",
    "                    else:\n",
    "                        obs_tensor = torch.FloatTensor(obs).unsqueeze(0).to(network.device)\n",
    "                        output = network(obs_tensor)\n",
    "                    \n",
    "                    if self.is_discrete:\n",
    "                        action = torch.argmax(output.squeeze()).item()\n",
    "                    else:\n",
    "                        action = output.cpu().numpy().flatten()\n",
    "                \n",
    "                # Step environment\n",
    "                obs, reward, terminated, truncated, _ = self.env.step(action)\n",
    "                done = terminated or truncated\n",
    "                episode_reward += reward\n",
    "            \n",
    "            total_reward += episode_reward\n",
    "        \n",
    "        return total_reward / n_episodes\n",
    "    \n",
    "    def evolve_generation_optimized(self, fitnesses: torch.Tensor) -> List[OptimizedNeuralNetwork]:\n",
    "        \"\"\"Optimized evolution with batch processing.\"\"\"\n",
    "        start_time = time.time()\n",
    "        new_population = []\n",
    "        \n",
    "        # Keep elite (fast copy)\n",
    "        if self.elite_size > 0:\n",
    "            _, elite_indices = torch.topk(fitnesses, self.elite_size)\n",
    "            for idx in elite_indices:\n",
    "                new_population.append(self.population[idx].clone_fast())\n",
    "        \n",
    "        # Apply operator pipelines with batch processing\n",
    "        remaining_size = self.population_size - len(new_population)\n",
    "        subpop_size = remaining_size // len(self.operators)\n",
    "        \n",
    "        for operator_pipeline in self.operators:\n",
    "            subpopulation = []\n",
    "            current_pop = self.population\n",
    "            current_fitnesses = fitnesses\n",
    "            \n",
    "            for operator in operator_pipeline:\n",
    "                \n",
    "                if isinstance(operator, (BestSelection, RandomSelection, \n",
    "                                       TournamentSelection, RouletteWheelSelection)):\n",
    "                    # Selection operator\n",
    "                    current_pop = operator(current_pop, current_fitnesses)\n",
    "                    \n",
    "                elif isinstance(operator, (AdditiveMutation, GlobalMutation, AdaptiveMutation)):\n",
    "                    # Mutation operator - batch process if possible\n",
    "                    if isinstance(operator, AdditiveMutation) and self.opt_config.use_batch_inference:\n",
    "                        # Use vectorized version\n",
    "                        vec_mutation = VectorizedAdditiveMutation(operator.mutation_rate, operator.mutation_strength)\n",
    "                        current_pop = vec_mutation(current_pop)\n",
    "                    else:\n",
    "                        # Fallback to original\n",
    "                        mutated = []\n",
    "                        for network in current_pop:\n",
    "                            mutated.append(operator(network))\n",
    "                        current_pop = mutated\n",
    "                    \n",
    "                elif isinstance(operator, (Crossover, UniformCrossover)):\n",
    "                    # Crossover operator\n",
    "                    offspring = []\n",
    "                    for i in range(0, len(current_pop) - 1, 2):\n",
    "                        child1, child2 = operator(current_pop[i], current_pop[i + 1])\n",
    "                        offspring.extend([child1, child2])\n",
    "                    if len(current_pop) % 2 == 1:\n",
    "                        offspring.append(current_pop[-1].clone_fast())\n",
    "                    current_pop = offspring\n",
    "            \n",
    "            # Add to new population\n",
    "            subpopulation = current_pop[:subpop_size]\n",
    "            new_population.extend(subpopulation)\n",
    "        \n",
    "        # Fill remaining slots if necessary\n",
    "        while len(new_population) < self.population_size:\n",
    "            idx = random.randint(0, len(new_population) - 1)\n",
    "            new_population.append(new_population[idx].clone_fast())\n",
    "        \n",
    "        self.timing_stats['evolution'].append(time.time() - start_time)\n",
    "        return new_population[:self.population_size]\n",
    "    \n",
    "    def train(\n",
    "        self, \n",
    "        n_generations: int = 100,\n",
    "        n_episodes_per_eval: int = 1,\n",
    "        verbose: bool = True,\n",
    "        save_best: bool = True,\n",
    "        checkpoint_interval: int = 10,\n",
    "        show_timing: bool = True\n",
    "    ) -> OptimizedNeuralNetwork:\n",
    "        \"\"\"Train with performance monitoring.\"\"\"\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Starting Optimized Neuroevolution Training\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Environment: {self.env_name}\")\n",
    "        print(f\"Population Size: {self.population_size}\")\n",
    "        print(f\"Optimization Settings:\")\n",
    "        print(f\"  - Parallel Evaluation: {self.opt_config.use_parallel_evaluation}\")\n",
    "        print(f\"  - Vectorized Environments: {self.opt_config.use_vectorized_env}\")\n",
    "        print(f\"  - Batch Inference: {self.opt_config.use_batch_inference}\")\n",
    "        print(f\"  - Memory Pooling: {self.opt_config.use_memory_pool}\")\n",
    "        print(f\"  - Device: {self.opt_config.device}\")\n",
    "        print(f\"  - Workers: {self.opt_config.num_workers if self.opt_config.use_parallel_evaluation else 'N/A'}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        total_start = time.time()\n",
    "        \n",
    "        for generation in range(n_generations):\n",
    "            gen_start = time.time()\n",
    "            self.generation = generation\n",
    "            \n",
    "            # Evaluate population\n",
    "            fitnesses = self.evaluate_population(n_episodes_per_eval)\n",
    "            \n",
    "            # Track best\n",
    "            best_idx = torch.argmax(fitnesses)\n",
    "            best_fitness = fitnesses[best_idx].item()\n",
    "            \n",
    "            if best_fitness > self.best_fitness:\n",
    "                self.best_fitness = best_fitness\n",
    "                self.best_network = self.population[best_idx].clone_fast()\n",
    "            \n",
    "            self.fitness_history.append({\n",
    "                'generation': generation,\n",
    "                'best': best_fitness,\n",
    "                'mean': fitnesses.mean().item(),\n",
    "                'std': fitnesses.std().item()\n",
    "            })\n",
    "            \n",
    "            # Evolve population\n",
    "            self.population = self.evolve_generation_optimized(fitnesses)\n",
    "            \n",
    "            gen_time = time.time() - gen_start\n",
    "            self.timing_stats['total'].append(gen_time)\n",
    "            \n",
    "            # Verbose output\n",
    "            if verbose:\n",
    "                if show_timing:\n",
    "                    eval_time = self.timing_stats['evaluation'][-1] if self.timing_stats['evaluation'] else 0\n",
    "                    evo_time = self.timing_stats['evolution'][-1] if self.timing_stats['evolution'] else 0\n",
    "                    print(f\"Gen {generation:3d} | \"\n",
    "                          f\"Best: {best_fitness:8.2f} | \"\n",
    "                          f\"Mean: {fitnesses.mean():8.2f} | \"\n",
    "                          f\"Std: {fitnesses.std():6.2f} | \"\n",
    "                          f\"Time: {gen_time:.2f}s (eval: {eval_time:.2f}s, evo: {evo_time:.2f}s)\")\n",
    "                else:\n",
    "                    print(f\"Gen {generation:3d} | \"\n",
    "                          f\"Best: {best_fitness:8.2f} | \"\n",
    "                          f\"Mean: {fitnesses.mean():8.2f} | \"\n",
    "                          f\"Std: {fitnesses.std():6.2f}\")\n",
    "            \n",
    "            # Save checkpoint\n",
    "            if save_best and generation % checkpoint_interval == 0:\n",
    "                self.save_checkpoint(f\"checkpoint_gen_{generation}.pt\")\n",
    "        \n",
    "        total_time = time.time() - total_start\n",
    "        \n",
    "        # Print performance summary\n",
    "        if show_timing:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Training Complete - Performance Summary\")\n",
    "            print(f\"{'='*60}\")\n",
    "            print(f\"Total Time: {total_time:.2f}s\")\n",
    "            print(f\"Generations/second: {n_generations/total_time:.2f}\")\n",
    "            print(f\"Average times per generation:\")\n",
    "            print(f\"  - Evaluation: {np.mean(self.timing_stats['evaluation']):.3f}s\")\n",
    "            print(f\"  - Evolution: {np.mean(self.timing_stats['evolution']):.3f}s\")\n",
    "            print(f\"  - Total: {np.mean(self.timing_stats['total']):.3f}s\")\n",
    "            print(f\"Best Fitness: {self.best_fitness:.2f}\")\n",
    "            print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        return self.best_network\n",
    "    \n",
    "    def save_checkpoint(self, filepath: str):\n",
    "        \"\"\"Save training checkpoint.\"\"\"\n",
    "        checkpoint = {\n",
    "            'generation': self.generation,\n",
    "            'best_fitness': self.best_fitness,\n",
    "            'best_network_state': self.best_network.state_dict() if self.best_network else None,\n",
    "            'fitness_history': self.fitness_history,\n",
    "            'network_config': self.network_config,\n",
    "            'timing_stats': self.timing_stats\n",
    "        }\n",
    "        torch.save(checkpoint, filepath)\n",
    "    \n",
    "    def cleanup(self):\n",
    "        \"\"\"Clean up resources.\"\"\"\n",
    "        if hasattr(self, 'pool'):\n",
    "            self.pool.close()\n",
    "            self.pool.join()\n",
    "        if hasattr(self, 'vec_evaluator'):\n",
    "            self.vec_evaluator.close()\n",
    "        self.env.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b81083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3691cfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evolving on CartPole-v1... (this may take time)\n",
      "Gen 1: best=95.000, mean=13.031\n",
      "Gen 2: best=121.000, mean=19.234\n",
      "Gen 3: best=133.000, mean=28.062\n",
      "Gen 4: best=259.000, mean=44.562\n",
      "Gen 5: best=500.000, mean=66.750\n",
      "Gen 6: best=500.000, mean=111.125\n",
      "Gen 7: best=500.000, mean=137.312\n",
      "Gen 8: best=500.000, mean=121.922\n",
      "Gen 9: best=500.000, mean=137.875\n",
      "Gen 10: best=500.000, mean=163.219\n",
      "Got best policy for CartPole. Test rollout:\n",
      "Test reward: 500.0\n",
      "Evolving on Pendulum-v1... (this may take time)\n",
      "Gen 1: best=-953.788, mean=-1326.220\n",
      "Gen 2: best=-947.359, mean=-1352.955\n",
      "Gen 3: best=-888.993, mean=-1345.063\n",
      "Gen 4: best=-827.014, mean=-1323.400\n",
      "Gen 5: best=-854.365, mean=-1351.682\n",
      "Gen 6: best=-850.263, mean=-1359.847\n",
      "Gen 7: best=-957.026, mean=-1318.800\n",
      "Gen 8: best=-735.171, mean=-1322.882\n",
      "Got best policy for Pendulum. Test rollout:\n",
      "Test reward (Pendulum): -1080.3916537719476\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Neuroevolution library for gymnasium-compatible environments.\n",
    "\n",
    "Features:\n",
    "- Lightweight neural network class with easy access to weights/biases and activations\n",
    "- Operator base class and a set of selection/mutation/crossover operators\n",
    "- Vectorized population representation using torch for GPU acceleration\n",
    "- Support for parallel evaluation using gymnasium Vector Envs (SyncVectorEnv/SubprocVectorEnv)\n",
    "- Example usages for discrete and continuous action spaces\n",
    "\n",
    "Notes:\n",
    "- The module focuses on speed and minimal copies. Parameter flatten/unflatten operations are vectorized.\n",
    "- The API aims to be flexible: operator_groups is a list of (selection, mutation, crossover, group_size)\n",
    "  where group_size can be absolute (int) or a fraction of population (float in (0,1]).\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import math\n",
    "import random\n",
    "from typing import Callable, List, Sequence, Tuple, Optional, Any\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Optional gymnasium import; keep it optional for other environments\n",
    "try:\n",
    "    import gymnasium as gym\n",
    "    from gymnasium.vector import SyncVectorEnv, AsyncVectorEnv\n",
    "except Exception:\n",
    "    gym = None\n",
    "    SyncVectorEnv = None\n",
    "    AsyncVectorEnv = None\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "#########################\n",
    "# Utility functions\n",
    "#########################\n",
    "\n",
    "def _to_tensor(x, dtype=torch.float32, device=DEVICE):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        return x.to(device)\n",
    "    return torch.tensor(x, dtype=dtype, device=device)\n",
    "\n",
    "\n",
    "def flatten_parameters(param_list: Sequence[torch.Tensor]) -> torch.Tensor:\n",
    "    \"\"\"Flatten a list of parameter tensors into a 1D tensor.\"\"\"\n",
    "    if not param_list:\n",
    "        return torch.tensor([], device=DEVICE)\n",
    "    return torch.cat([p.contiguous().view(-1) for p in param_list], dim=0)\n",
    "\n",
    "\n",
    "def unflatten_parameters(flat: torch.Tensor, shapes: Sequence[Tuple[int, ...]]) -> List[torch.Tensor]:\n",
    "    \"\"\"Unflatten a 1D tensor into list of tensors with shapes.\n",
    "\n",
    "    Args:\n",
    "        flat: 1D tensor containing all parameters.\n",
    "        shapes: sequence of shapes for tensors.\n",
    "    Returns:\n",
    "        list of tensors reshaped accordingly.\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    idx = 0\n",
    "    for s in shapes:\n",
    "        n = int(np.prod(s))\n",
    "        chunk = flat[idx: idx + n]\n",
    "        out.append(chunk.view(*s))\n",
    "        idx += n\n",
    "    return out\n",
    "\n",
    "\n",
    "#########################\n",
    "# Neural Network class\n",
    "#########################\n",
    "class BatchedNet:\n",
    "    \"\"\"Batched forward for SimpleNet-like MLP with per-sample parameters.\"\"\"\n",
    "\n",
    "    def __init__(self, layer_sizes: Sequence[int], activation=F.tanh, output_activation=None, device=DEVICE):\n",
    "        self.layer_sizes = list(layer_sizes)\n",
    "        self.activation = activation\n",
    "        self.output_activation = output_activation\n",
    "        self.device = device\n",
    "\n",
    "        # shapes and flat slicing plan (weights first, then biases) matching SimpleNet\n",
    "        self._shapes_w = []\n",
    "        self._shapes_b = []\n",
    "        for i in range(len(layer_sizes)-1):\n",
    "            in_dim = layer_sizes[i]\n",
    "            out_dim = layer_sizes[i+1]\n",
    "            self._shapes_w.append((out_dim, in_dim))\n",
    "            self._shapes_b.append((out_dim,))\n",
    "        # precompute flat indices\n",
    "        self._idx = []\n",
    "        off = 0\n",
    "        for s in self._shapes_w + self._shapes_b:\n",
    "            n = int(np.prod(s))\n",
    "            self._idx.append((off, off+n, s))\n",
    "            off += n\n",
    "        self.genome_dim = off\n",
    "\n",
    "    def split_params(self, P_params: torch.Tensor) -> Tuple[List[torch.Tensor], List[torch.Tensor]]:\n",
    "        \"\"\"\n",
    "        P_params: (P, D) flat genomes (weights then biases).\n",
    "        Returns:\n",
    "            Ws: list of (P, out, in)\n",
    "            Bs: list of (P, out)\n",
    "        \"\"\"\n",
    "        assert P_params.dim() == 2 and P_params.size(1) == self.genome_dim\n",
    "        Ws, Bs = [], []\n",
    "        for k, (start, end, shape) in enumerate(self._idx):\n",
    "            part = P_params[:, start:end].view(P_params.size(0), *shape)\n",
    "            (Ws if k < len(self._shapes_w) else Bs).append(part)\n",
    "        return Ws, Bs\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward_batch(self, x: torch.Tensor, Ws: List[torch.Tensor], Bs: List[torch.Tensor]) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        x: (B, in) observations\n",
    "        Ws: [ (B, out, in), ... ]\n",
    "        Bs: [ (B, out), ... ]\n",
    "        returns: (B, out_last)\n",
    "        \"\"\"\n",
    "        h = x\n",
    "        L = len(Ws)\n",
    "        for i in range(L):\n",
    "            # h: (B, in_i); W: (B, out_i, in_i); b: (B, out_i)\n",
    "            # out[b] = W[b] @ h[b] + b[b]\n",
    "            # -> use bmm: (B,1,in) x (B,in,out) -> (B,1,out) -> squeeze\n",
    "            h = torch.bmm(h.unsqueeze(1), Ws[i].transpose(1, 2)).squeeze(1) + Bs[i]\n",
    "            if i < L - 1:\n",
    "                h = self.activation(h)\n",
    "            elif self.output_activation is not None:\n",
    "                h = self.output_activation(h)\n",
    "        return h\n",
    "\n",
    "class SimpleNet:\n",
    "    \"\"\"Simple fully-connected network with easy access to weights/biases.\n",
    "\n",
    "    The network stores weights and biases as lists of tensors. Provides\n",
    "    methods to get/set flattened parameters and to run forward passes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layer_sizes: Sequence[int], activation: Callable = F.tanh, output_activation: Optional[Callable] = None, device: torch.device = DEVICE):\n",
    "        assert len(layer_sizes) >= 2\n",
    "        self.layer_sizes = list(layer_sizes)\n",
    "        self.activation = activation\n",
    "        self.output_activation = output_activation\n",
    "        self.device = device\n",
    "\n",
    "        # Initialize weights and biases\n",
    "        self.weights: List[torch.Tensor] = []\n",
    "        self.biases: List[torch.Tensor] = []\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            in_dim = layer_sizes[i]\n",
    "            out_dim = layer_sizes[i + 1]\n",
    "            # Xavier initialization\n",
    "            w = torch.randn(out_dim, in_dim, device=self.device) * math.sqrt(2.0 / (in_dim + out_dim))\n",
    "            b = torch.zeros(out_dim, device=self.device)\n",
    "            self.weights.append(w)\n",
    "            self.biases.append(b)\n",
    "\n",
    "        # Cache shapes for flatten/unflatten\n",
    "        self._param_shapes = [tuple(w.shape) for w in self.weights] + [tuple(b.shape) for b in self.biases]\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = x.to(self.device)\n",
    "        for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
    "            x = F.linear(x, w, b)\n",
    "            if i < len(self.weights) - 1:\n",
    "                x = self.activation(x)\n",
    "            else:\n",
    "                if self.output_activation is not None:\n",
    "                    x = self.output_activation(x)\n",
    "        return x\n",
    "\n",
    "    def get_flat_params(self) -> torch.Tensor:\n",
    "        \"\"\"Return flattened parameters (weights then biases).\"\"\"\n",
    "        # Guarantee contiguous\n",
    "        parts = [p.contiguous().view(-1) for p in self.weights + self.biases]\n",
    "        if parts:\n",
    "            return torch.cat(parts, dim=0).detach().clone().to(self.device)\n",
    "        else:\n",
    "            return torch.empty(0, device=self.device)\n",
    "\n",
    "    def set_flat_params(self, flat: torch.Tensor):\n",
    "        \"\"\"Set parameters from a flat 1D tensor.\"\"\"\n",
    "        assert flat.numel() == sum(int(np.prod(s)) for s in self._param_shapes)\n",
    "        parts = unflatten_parameters(flat, self._param_shapes)\n",
    "        n_w = len(self.weights)\n",
    "        for i in range(n_w):\n",
    "            self.weights[i].data.copy_(parts[i])\n",
    "        for j in range(len(self.biases)):\n",
    "            self.biases[j].data.copy_(parts[n_w + j])\n",
    "\n",
    "    def num_params(self) -> int:\n",
    "        return sum(int(np.prod(s)) for s in self._param_shapes)\n",
    "\n",
    "    def cpu(self):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] = self.weights[i].cpu()\n",
    "        for i in range(len(self.biases)):\n",
    "            self.biases[i] = self.biases[i].cpu()\n",
    "        self.device = torch.device(\"cpu\")\n",
    "\n",
    "    def to(self, device: torch.device):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] = self.weights[i].to(device)\n",
    "        for i in range(len(self.biases)):\n",
    "            self.biases[i] = self.biases[i].to(device)\n",
    "        self.device = device\n",
    "\n",
    "\n",
    "#########################\n",
    "# Operator base classes\n",
    "#########################\n",
    "\n",
    "class Operator:\n",
    "    \"\"\"Base operator class. Subclasses should implement __call__.\n",
    "\n",
    "    The operator is expected to accept and return the flat population tensor (P, genome_dim)\n",
    "    along with fitnesses if needed.\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, population: torch.Tensor, fitness: Optional[torch.Tensor] = None, **kwargs) -> torch.Tensor:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "#########################\n",
    "# Mutations\n",
    "#########################\n",
    "\n",
    "class AdditiveMutation(Operator):\n",
    "    \"\"\"Additive Gaussian mutation applied elementwise with a probability per ge\n",
    "\n",
    "    Args:\n",
    "        mutation_rate: probability that any given gene is mutated.\n",
    "        sigma: standard deviation of additive noise.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mutation_rate: float = 0.01, sigma: float = 0.1, device: torch.device = DEVICE):\n",
    "        self.mutation_rate = float(mutation_rate)\n",
    "        self.sigma = float(sigma)\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, population: torch.Tensor, fitness: Optional[torch.Tensor] = None, **kwargs) -> torch.Tensor:\n",
    "        # population: (P, D)\n",
    "        P, D = population.shape\n",
    "        mask = torch.rand((P, D), device=self.device) < self.mutation_rate\n",
    "        noise = torch.randn((P, D), device=self.device) * self.sigma\n",
    "        out = population.clone()\n",
    "        out[mask] += noise[mask]\n",
    "        return out\n",
    "\n",
    "\n",
    "class GlobalMutation(Operator):\n",
    "    \"\"\"Replace entire genome with noise scaled by sigma with probability mutation_prob per individual.\n",
    "\n",
    "    Args:\n",
    "        mutation_prob: probability an individual is fully replaced (exploration).\n",
    "        sigma: noise std\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mutation_prob: float = 0.05, sigma: float = 1.0, device: torch.device = DEVICE):\n",
    "        self.mutation_prob = float(mutation_prob)\n",
    "        self.sigma = float(sigma)\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, population: torch.Tensor, fitness: Optional[torch.Tensor] = None, **kwargs) -> torch.Tensor:\n",
    "        P, D = population.shape\n",
    "        out = population.clone()\n",
    "        mask = torch.rand(P, device=self.device) < self.mutation_prob\n",
    "        if mask.any():\n",
    "            noise = torch.randn((mask.sum().item(), D), device=self.device) * self.sigma\n",
    "            out[mask] = out[mask] + noise\n",
    "        return out\n",
    "\n",
    "\n",
    "#########################\n",
    "# Crossovers\n",
    "#########################\n",
    "\n",
    "class XPointCrossover(Operator):\n",
    "    \"\"\"X-point crossover on flattened genomes.\n",
    "\n",
    "    Args:\n",
    "        x: number of crossover points (>=1)\n",
    "        prob: probability of crossover between a pair\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x: int = 1, prob: float = 0.9, device: torch.device = DEVICE):\n",
    "        assert x >= 1\n",
    "        self.x = x\n",
    "        self.prob = float(prob)\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, population: torch.Tensor, fitness: Optional[torch.Tensor] = None, **kwargs) -> torch.Tensor:\n",
    "        # population (P, D)\n",
    "        P, D = population.shape\n",
    "        out = population.clone()\n",
    "        # Shuffle indices to create random pairs\n",
    "        idx = torch.randperm(P, device=self.device)\n",
    "        for i in range(0, P - 1, 2):\n",
    "            if random.random() > self.prob:\n",
    "                continue\n",
    "            a = idx[i].item()\n",
    "            b = idx[i + 1].item()\n",
    "            points = sorted(random.sample(range(1, D), k=min(self.x, D - 1)))\n",
    "            # perform x-point crossover\n",
    "            last = 0\n",
    "            src_a = out[a].clone()\n",
    "            src_b = out[b].clone()\n",
    "            take_from_a = True\n",
    "            for p in points + [D]:\n",
    "                if take_from_a:\n",
    "                    out[a, last:p] = src_a[last:p]\n",
    "                    out[b, last:p] = src_b[last:p]\n",
    "                else:\n",
    "                    out[a, last:p] = src_b[last:p]\n",
    "                    out[b, last:p] = src_a[last:p]\n",
    "                take_from_a = not take_from_a\n",
    "                last = p\n",
    "        return out\n",
    "\n",
    "\n",
    "#########################\n",
    "# Selections\n",
    "#########################\n",
    "\n",
    "class BestSelection(Operator):\n",
    "    \"\"\"Select top-k individuals (elitism).\n",
    "\n",
    "    Args:\n",
    "        k: number of individuals to keep.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k: int = 2, device: torch.device = DEVICE):\n",
    "        self.k = int(k)\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, population: torch.Tensor, fitness: Optional[torch.Tensor] = None, **kwargs) -> torch.Tensor:\n",
    "        assert fitness is not None\n",
    "        P = population.shape[0]\n",
    "        k = min(self.k, P)\n",
    "        _, idx = torch.topk(fitness, k=k, largest=True)\n",
    "        return population[idx]\n",
    "\n",
    "\n",
    "class RandomSelection(Operator):\n",
    "    \"\"\"Randomly select n individuals.\"\"\"\n",
    "\n",
    "    def __init__(self, n: int = 1, device: torch.device = DEVICE):\n",
    "        self.n = int(n)\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, population: torch.Tensor, fitness: Optional[torch.Tensor] = None, **kwargs) -> torch.Tensor:\n",
    "        P = population.shape[0]\n",
    "        n = min(self.n, P)\n",
    "        idx = torch.randperm(P, device=self.device)[:n]\n",
    "        return population[idx]\n",
    "\n",
    "\n",
    "class TournamentSelection(Operator):\n",
    "    \"\"\"Tournament selection: pick n winners by running tournaments of size t.\"\"\"\n",
    "\n",
    "    def __init__(self, n: int = 1, t: int = 3, device: torch.device = DEVICE):\n",
    "        self.n = int(n)\n",
    "        self.t = int(t)\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, population: torch.Tensor, fitness: Optional[torch.Tensor] = None, **kwargs) -> torch.Tensor:\n",
    "        assert fitness is not None\n",
    "        P = population.shape[0]\n",
    "        winners = []\n",
    "        for _ in range(self.n):\n",
    "            participants = torch.randint(0, P, (self.t,), device=self.device)\n",
    "            best = participants[torch.argmax(fitness[participants])]\n",
    "            winners.append(best.item())\n",
    "        return population[torch.tensor(winners, device=self.device)]\n",
    "\n",
    "\n",
    "class RouletteSelection(Operator):\n",
    "    \"\"\"Roulette wheel (fitness-proportionate) selection of n individuals.\"\"\"\n",
    "\n",
    "    def __init__(self, n: int = 1, device: torch.device = DEVICE):\n",
    "        self.n = int(n)\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, population: torch.Tensor, fitness: Optional[torch.Tensor] = None, **kwargs) -> torch.Tensor:\n",
    "        assert fitness is not None\n",
    "        # Shift fitness to be positive\n",
    "        f = fitness.clone()\n",
    "        minf = float(f.min())\n",
    "        if minf <= 0:\n",
    "            f = f - minf + 1e-6\n",
    "        probs = f / f.sum()\n",
    "        idx = torch.multinomial(probs, self.n, replacement=True)\n",
    "        return population[idx]\n",
    "\n",
    "\n",
    "#########################\n",
    "# Neuroevolution core\n",
    "#########################\n",
    "\n",
    "class Neuroevolution:\n",
    "    \"\"\"Main neuroevolution optimizer.\n",
    "\n",
    "    This class keeps a flattened population of genomes and applies selection, crossover, and mutation\n",
    "    operators to evolve solutions for a given environment.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        env_maker: Callable[[], Any],\n",
    "        population_size: int = 128,\n",
    "        net_arch: Sequence[int] = (4, 16, 2),\n",
    "        device: torch.device = DEVICE,\n",
    "        operator_groups: Optional[List[Tuple[Operator, Operator, Operator, Any]]] = None,\n",
    "        elite_fraction: float = 0.02,\n",
    "        seed: Optional[int] = None,\n",
    "    ):\n",
    "        \"\"\"Initialize the optimizer.\n",
    "\n",
    "        Args:\n",
    "            env_maker: callable that returns a fresh environment instance.\n",
    "            population_size: number of individuals.\n",
    "            net_arch: network layer sizes (input,...,output)\n",
    "            operator_groups: list of tuples (selection, mutation, crossover, group_size) defining how\n",
    "                             offspring are produced. group_size can be int or fraction.\n",
    "            elite_fraction: fraction of population preserved as elites.\n",
    "        \"\"\"\n",
    "        if seed is not None:\n",
    "            torch.manual_seed(seed)\n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        self.env_maker = env_maker\n",
    "        self.population_size = int(population_size)\n",
    "        self.device = device\n",
    "        self.net_arch = list(net_arch)\n",
    "\n",
    "        # single example net to know parameter shapes\n",
    "        tmp = SimpleNet(net_arch, device=self.device)\n",
    "        self.genome_dim = tmp.num_params()\n",
    "        del tmp\n",
    "\n",
    "        # initialize flat population (P, D)\n",
    "        self.population = torch.randn((self.population_size, self.genome_dim), device=self.device) * 0.1\n",
    "\n",
    "        # operator groups\n",
    "        if operator_groups is None:\n",
    "            # default: tournament selection + additive mutation + 1-point crossover\n",
    "            operator_groups = [\n",
    "                (TournamentSelection(n=population_size // 2, t=3, device=device), AdditiveMutation(0.02, 0.05, device=device), XPointCrossover(1, 0.9, device=device), population_size // 2),\n",
    "            ]\n",
    "        self.operator_groups = operator_groups\n",
    "\n",
    "        self.elite_fraction = float(elite_fraction)\n",
    "        self.num_elites = max(1, int(math.ceil(self.elite_fraction * self.population_size)))\n",
    "\n",
    "    def _make_vector_env(self, n_envs: int):\n",
    "        if gym is None:\n",
    "            raise RuntimeError(\"gymnasium not available. Provide env_maker that returns an env-like object\")\n",
    "        # create list of env maker functions\n",
    "        fns = [self.env_maker for _ in range(n_envs)]\n",
    "        # prefer AsyncVectorEnv if available (subprocess) for CPU-bound envs\n",
    "        try:\n",
    "            return AsyncVectorEnv(fns)\n",
    "        except Exception:\n",
    "            return SyncVectorEnv(fns)\n",
    "        \n",
    "    def _evaluate_population_vectorized(self, population: torch.Tensor, episodes: int = 1) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Evaluate population with parallel envs and batched forward.\n",
    "        One episode per individual (repeat 'episodes' if you wish; here we average over them).\n",
    "        \"\"\"\n",
    "        P = population.shape[0]\n",
    "        fitness = torch.zeros(P, device=self.device)\n",
    "\n",
    "        # You can tune this; larger is faster until env-CPU becomes bottleneck\n",
    "        max_batch = min(64, P)\n",
    "\n",
    "        batched = BatchedNet(self.net_arch, device=self.device)\n",
    "\n",
    "        for start in range(0, P, max_batch):\n",
    "            end = min(P, start + max_batch)\n",
    "            batch_genomes = population[start:end]                      # (B, D)\n",
    "            B = batch_genomes.size(0)\n",
    "            Ws, Bs = batched.split_params(batch_genomes)               # per-layer (B, ...)\n",
    "\n",
    "            # ---- Run 'episodes' times and average\n",
    "            batch_returns = torch.zeros(B, device=self.device)\n",
    "            for _ in range(episodes):\n",
    "                # Try VectorEnv first\n",
    "                use_vector = (gym is not None) and (SyncVectorEnv is not None)\n",
    "                if use_vector:\n",
    "                    try:\n",
    "                        vec = self._make_vector_env(B)  # AsyncVectorEnv preferred by your helper\n",
    "                        obs, _ = vec.reset()\n",
    "                        # Convert to torch\n",
    "                        obs_t = torch.as_tensor(obs, dtype=torch.float32, device=self.device)  # (B, obs_dim)\n",
    "                        done = torch.zeros(B, dtype=torch.bool, device=self.device)\n",
    "                        ep_ret = torch.zeros(B, device=self.device)\n",
    "\n",
    "                        while not bool(done.all()):\n",
    "                            # Compute actions for *all* envs, but mask-out finished ones\n",
    "                            logits = batched.forward_batch(obs_t, Ws, Bs)  # (B, act_dim or 1)\n",
    "\n",
    "                            if hasattr(vec.single_action_space, \"n\"):\n",
    "                                # Discrete: pick argmax\n",
    "                                acts = torch.argmax(logits, dim=-1).to(torch.int64)  # (B,)\n",
    "                                # Replace actions for finished envs with a valid dummy (e.g., 0)\n",
    "                                if done.any():\n",
    "                                    acts = acts.masked_fill(done, 0)\n",
    "                                actions_np = acts.detach().cpu().numpy()\n",
    "                            else:\n",
    "                                # Continuous: tanh to [-1,1], then scale to box if needed\n",
    "                                cont = torch.tanh(logits)\n",
    "                                high = torch.as_tensor(vec.single_action_space.high, device=self.device, dtype=torch.float32)\n",
    "                                low  = torch.as_tensor(vec.single_action_space.low,  device=self.device, dtype=torch.float32)\n",
    "                                scaled = low + (cont + 1.0) * 0.5 * (high - low)     # (B, act_dim)\n",
    "                                if done.any():\n",
    "                                    # keep finished envs frozen with zeros\n",
    "                                    scaled = torch.where(done.unsqueeze(-1), torch.zeros_like(scaled), scaled)\n",
    "                                actions_np = scaled.detach().cpu().numpy()\n",
    "\n",
    "                            # Step vector env\n",
    "                            next_obs, rews, terms, truncs, infos = vec.step(actions_np)\n",
    "\n",
    "                            # Update trackers\n",
    "                            ep_ret += torch.as_tensor(rews, device=self.device, dtype=torch.float32)\n",
    "                            new_done = torch.as_tensor(terms, device=self.device, dtype=torch.bool) | \\\n",
    "                                      torch.as_tensor(truncs, device=self.device, dtype=torch.bool)\n",
    "                            done = done | new_done\n",
    "\n",
    "                            # For envs that finished, their next_obs is undefined until reset; freeze them\n",
    "                            obs_t = torch.as_tensor(next_obs, dtype=torch.float32, device=self.device)\n",
    "                            # Optional: if your vec env requires manual reset for finished envs before next step,\n",
    "                            # do it here. Many Gymnasium VectorEnvs allow stepping again after done only after reset;\n",
    "                            # if you see errors, replace the loop body with:\n",
    "                            #   idx = torch.where(~done)[0].cpu().numpy().tolist()\n",
    "                            #   compute actions only for idx, and call vec.step() on those envs via a manual list fallback.\n",
    "\n",
    "                        vec.close()\n",
    "                        batch_returns += ep_ret\n",
    "                    except Exception:\n",
    "                        # Fallback to manual list of envs if vector env semantics differ\n",
    "                        use_vector = False\n",
    "\n",
    "                if not use_vector:\n",
    "                    # ---- Fallback: list of envs; still one batched forward per step\n",
    "                    envs = [self.env_maker() for _ in range(B)]\n",
    "                    obs = []\n",
    "                    for e in envs:\n",
    "                        o, _ = e.reset()\n",
    "                        obs.append(o)\n",
    "                    obs_t = torch.as_tensor(np.array(obs), dtype=torch.float32, device=self.device)\n",
    "                    done = torch.zeros(B, dtype=torch.bool, device=self.device)\n",
    "                    ep_ret = torch.zeros(B, device=self.device)\n",
    "\n",
    "                    while not bool(done.all()):\n",
    "                        logits = batched.forward_batch(obs_t, Ws, Bs)\n",
    "                        if hasattr(envs[0].action_space, \"n\"):\n",
    "                            acts = torch.argmax(logits, dim=-1).to(torch.int64).detach().cpu().numpy()\n",
    "                        else:\n",
    "                            cont = torch.tanh(logits).detach().cpu().numpy()\n",
    "\n",
    "                        next_obs_list = []\n",
    "                        for i, env in enumerate(envs):\n",
    "                            if done[i]:\n",
    "                                next_obs_list.append(obs_t[i].detach().cpu().numpy())\n",
    "                                continue\n",
    "                            if hasattr(env.action_space, \"n\"):\n",
    "                                a = int(acts[i])\n",
    "                            else:\n",
    "                                # scale if needed\n",
    "                                a = cont[i]\n",
    "                                if hasattr(env.action_space, \"high\"):\n",
    "                                    high = np.array(env.action_space.high, dtype=np.float32)\n",
    "                                    low  = np.array(env.action_space.low,  dtype=np.float32)\n",
    "                                    a = low + (a + 1.0) * 0.5 * (high - low)\n",
    "                            o, r, term, trunc, _ = env.step(a)\n",
    "                            ep_ret[i] += float(r)\n",
    "                            done[i] = bool(term) or bool(trunc)\n",
    "                            next_obs_list.append(o)\n",
    "                        obs_t = torch.as_tensor(np.array(next_obs_list), dtype=torch.float32, device=self.device)\n",
    "\n",
    "                    for e in envs:\n",
    "                        e.close()\n",
    "                    batch_returns += ep_ret\n",
    "\n",
    "            # average over episodes\n",
    "            fitness[start:end] = batch_returns / float(episodes)\n",
    "\n",
    "        return fitness\n",
    "    \n",
    "    def _evaluate_population(self, population: torch.Tensor, episodes: int = 1, render: bool = False) -> torch.Tensor:\n",
    "        \"\"\"Evaluate each individual in the population on the environment and return fitness scores.\n",
    "\n",
    "        This implementation runs evaluations sequentially by default but can be vectorized externally.\n",
    "        \"\"\"\n",
    "        P = population.shape[0]\n",
    "        fitnesses = torch.zeros(P, device=self.device)\n",
    "\n",
    "        # We'll evaluate individuals using a vectorized env in batches for speed\n",
    "        batch_size = min(8, P)  # configurable\n",
    "\n",
    "        net = SimpleNet(self.net_arch, device=self.device)\n",
    "\n",
    "        for start in range(0, P, batch_size):\n",
    "            end = min(P, start + batch_size)\n",
    "            batch = population[start:end]\n",
    "            bsize = end - start\n",
    "            # for each in batch evaluate episodes times\n",
    "            batch_f = torch.zeros(bsize, device=self.device)\n",
    "            for i in range(bsize):\n",
    "                genome = batch[i]\n",
    "                net.set_flat_params(genome)\n",
    "                total_reward = 0.0\n",
    "                for ep in range(episodes):\n",
    "                    env = self.env_maker()\n",
    "                    obs, _ = env.reset()\n",
    "                    done = False\n",
    "                    ep_reward = 0.0\n",
    "                    while True:\n",
    "                        x = torch.tensor(obs, dtype=torch.float32, device=self.device).unsqueeze(0)\n",
    "                        out = net.forward(x).squeeze(0)\n",
    "                        # map out to action depending on env action space\n",
    "                        if hasattr(env, \"action_space\"):\n",
    "                            a_space = env.action_space\n",
    "                            if hasattr(a_space, \"n\"):\n",
    "                                # discrete\n",
    "                                action = int(torch.argmax(out).item())\n",
    "                            else:\n",
    "                                # continuous\n",
    "                                # assume action in [-1,1]\n",
    "                                action = out.cpu().numpy()\n",
    "                                # scale if necessary\n",
    "                                if hasattr(a_space, \"high\"):\n",
    "                                    high = np.array(a_space.high, dtype=np.float32)\n",
    "                                    low = np.array(a_space.low, dtype=np.float32)\n",
    "                                    # tanh to -1..1\n",
    "                                    action = np.tanh(action)\n",
    "                                    action = low + (action + 1.0) * 0.5 * (high - low)\n",
    "                                else:\n",
    "                                    action = np.tanh(action)\n",
    "                        else:\n",
    "                            # fallback: use continuous output\n",
    "                            action = out.cpu().numpy()\n",
    "\n",
    "                        obs, reward, terminated, truncated, info = env.step(action)\n",
    "                        ep_reward += float(reward)\n",
    "                        if terminated or truncated:\n",
    "                            break\n",
    "                    total_reward += ep_reward\n",
    "                    env.close()\n",
    "                batch_f[i] = float(total_reward / episodes)\n",
    "            fitnesses[start:end] = batch_f\n",
    "        return fitnesses\n",
    "\n",
    "    def step(self, generations: int = 1, episodes: int = 1, verbose: bool = True):\n",
    "        \"\"\"Run evolution for given number of generations.\"\"\"\n",
    "        for gen in range(1, generations + 1):\n",
    "            fitness = self._evaluate_population_vectorized(self.population, episodes=episodes)\n",
    "            # sort population by fitness\n",
    "            sorted_fitness, idx = torch.sort(fitness, descending=True)\n",
    "            pop_sorted = self.population[idx]\n",
    "\n",
    "            # elites carried over\n",
    "            elites = pop_sorted[: self.num_elites]\n",
    "\n",
    "            # build new population\n",
    "            new_pop = [elites]\n",
    "            remaining = self.population_size - self.num_elites\n",
    "\n",
    "            # allocate group sizes\n",
    "            group_allocs = []\n",
    "            total_frac = 0.0\n",
    "            for sel, mut, cross, group_size in self.operator_groups:\n",
    "                if isinstance(group_size, float):\n",
    "                    alloc = int(group_size * remaining)\n",
    "                else:\n",
    "                    alloc = int(group_size)\n",
    "                group_allocs.append((sel, mut, cross, alloc))\n",
    "            # adjust rounding\n",
    "            total_alloc = sum(g[3] for g in group_allocs)\n",
    "            if total_alloc < remaining:\n",
    "                group_allocs[0] = (group_allocs[0][0], group_allocs[0][1], group_allocs[0][2], group_allocs[0][3] + (remaining - total_alloc))\n",
    "\n",
    "            for sel, mut, cross, alloc in group_allocs:\n",
    "                if alloc <= 0:\n",
    "                    continue\n",
    "                # selection returns selected parents (M, D)\n",
    "                parents = sel(pop_sorted, sorted_fitness)\n",
    "                # if parents less than alloc, sample with replacement\n",
    "                if parents.shape[0] == 0:\n",
    "                    parents = pop_sorted[torch.randperm(pop_sorted.shape[0], device=self.device)[:max(1, alloc)]]\n",
    "                # expand parents to have size alloc (simple sampling)\n",
    "                idxs = torch.randint(0, parents.shape[0], (alloc,), device=self.device)\n",
    "                children = parents[idxs]\n",
    "                # crossover\n",
    "                if cross is not None:\n",
    "                    children = cross(children)\n",
    "                # mutation\n",
    "                if mut is not None:\n",
    "                    children = mut(children)\n",
    "                new_pop.append(children)\n",
    "\n",
    "            new_pop = torch.cat(new_pop, dim=0)\n",
    "            # safety: trim or pad\n",
    "            if new_pop.shape[0] > self.population_size:\n",
    "                new_pop = new_pop[: self.population_size]\n",
    "            elif new_pop.shape[0] < self.population_size:\n",
    "                pad = torch.randn((self.population_size - new_pop.shape[0], self.genome_dim), device=self.device) * 0.01\n",
    "                new_pop = torch.cat([new_pop, pad], dim=0)\n",
    "\n",
    "            self.population = new_pop\n",
    "\n",
    "            if verbose:\n",
    "                best = float(sorted_fitness[0].item())\n",
    "                mean = float(fitness.mean().item())\n",
    "                print(f\"Gen {gen}: best={best:.3f}, mean={mean:.3f}\")\n",
    "\n",
    "    def get_best(self) -> SimpleNet:\n",
    "        fitness = self._evaluate_population(self.population, episodes=1)\n",
    "        best_idx = int(torch.argmax(fitness).item())\n",
    "        genome = self.population[best_idx]\n",
    "        net = SimpleNet(self.net_arch, device=self.device)\n",
    "        net.set_flat_params(genome)\n",
    "        return net\n",
    "\n",
    "\n",
    "#########################\n",
    "# Examples\n",
    "#########################\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example 1: CartPole-v1 (discrete action)\n",
    "    if gym is not None:\n",
    "        def make_cartpole():\n",
    "            return gym.make(\"CartPole-v1\")\n",
    "\n",
    "        evo = Neuroevolution(\n",
    "            env_maker=make_cartpole,\n",
    "            population_size=64,\n",
    "            net_arch=(4, 32, 2),\n",
    "            operator_groups=[\n",
    "                (TournamentSelection(n=32, t=3), AdditiveMutation(0.02, 0.1), XPointCrossover(1, 0.9), 32),\n",
    "                (RandomSelection(n=32), GlobalMutation(0.02, 0.5), XPointCrossover(2, 0.7), 32),\n",
    "            ],\n",
    "            elite_fraction=0.05,\n",
    "        )\n",
    "\n",
    "        print(\"Evolving on CartPole-v1... (this may take time)\")\n",
    "        evo.step(generations=10, episodes=1)\n",
    "        best_net = evo.get_best()\n",
    "        print(\"Got best policy for CartPole. Test rollout:\")\n",
    "        env = make_cartpole()\n",
    "        obs, _ = env.reset()\n",
    "        done = False\n",
    "        tot = 0.0\n",
    "        while True:\n",
    "            x = torch.tensor(obs, dtype=torch.float32).unsqueeze(0)\n",
    "            out = best_net.forward(x).squeeze(0)\n",
    "            action = int(torch.argmax(out).item())\n",
    "            obs, reward, terminated, truncated, info = env.step(action)\n",
    "            tot += reward\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "        print(f\"Test reward: {tot}\")\n",
    "\n",
    "        env.close()\n",
    "\n",
    "    # Example 2: Pendulum-v1 (continuous)\n",
    "    if gym is not None:\n",
    "        def make_pendulum():\n",
    "            return gym.make(\"Pendulum-v1\")\n",
    "\n",
    "        evo_c = Neuroevolution(\n",
    "            env_maker=make_pendulum,\n",
    "            population_size=64,\n",
    "            net_arch=(3, 32, 1),\n",
    "            operator_groups=[\n",
    "                (TournamentSelection(n=32, t=3), AdditiveMutation(0.05, 0.2), XPointCrossover(2, 0.8), 32),\n",
    "                (RandomSelection(n=32), GlobalMutation(0.05, 1.0), XPointCrossover(3, 0.6), 32),\n",
    "            ],\n",
    "            elite_fraction=0.05,\n",
    "        )\n",
    "\n",
    "        print(\"Evolving on Pendulum-v1... (this may take time)\")\n",
    "        evo_c.step(generations=8, episodes=1)\n",
    "        best_pend = evo_c.get_best()\n",
    "        print(\"Got best policy for Pendulum. Test rollout:\")\n",
    "        env = make_pendulum()\n",
    "        obs, _ = env.reset()\n",
    "        tot = 0.0\n",
    "        while True:\n",
    "            x = torch.tensor(obs, dtype=torch.float32).unsqueeze(0)\n",
    "            out = best_pend.forward(x).squeeze(0)\n",
    "            action = np.tanh(out.cpu().numpy())\n",
    "            obs, reward, terminated, truncated, info = env.step(action)\n",
    "            tot += reward\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "        print(f\"Test reward (Pendulum): {tot}\")\n",
    "        env.close()\n",
    "\n",
    "    print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4a60ae4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen 1: best=73.000, mean=15.531\n",
      "\n",
      "=== cProfile top 40 by cumulative time ===\n",
      "         170291 function calls (167230 primitive calls) in 0.116 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "   List reduced from 298 to 40 due to restriction <40>\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.116    0.116 /tmp/ipykernel_1891186/376842627.py:481(step)\n",
      "    536/7    0.001    0.000    0.116    0.017 /tmp/ipykernel_1891186/3689267830.py:35(wrapped)\n",
      "        1    0.003    0.003    0.113    0.113 /tmp/ipykernel_1891186/376842627.py:417(_evaluate_population)\n",
      "     2194    0.001    0.000    0.037    0.000 /tmp/ipykernel_1891186/3689267830.py:29(_sync_cuda)\n",
      "     2194    0.003    0.000    0.029    0.000 /home/urkui-3/miniconda3/envs/env_isaaclab/lib/python3.10/site-packages/torch/cuda/__init__.py:944(synchronize)\n",
      "      561    0.001    0.000    0.028    0.000 /tmp/ipykernel_1891186/3689267830.py:88(_wrap_env_method)\n",
      "      497    0.000    0.000    0.023    0.000 /tmp/ipykernel_1891186/3689267830.py:81(<lambda>)\n",
      "      497    0.002    0.000    0.017    0.000 /tmp/ipykernel_1891186/376842627.py:111(forward)\n",
      "     2194    0.001    0.000    0.016    0.000 /home/urkui-3/miniconda3/envs/env_isaaclab/lib/python3.10/site-packages/torch/cuda/__init__.py:439(__init__)\n",
      "     2194    0.002    0.000    0.015    0.000 /home/urkui-3/miniconda3/envs/env_isaaclab/lib/python3.10/site-packages/torch/cuda/_utils.py:9(_get_device_index)\n",
      "       32    0.000    0.000    0.013    0.000 /tmp/ipykernel_1891186/3689267830.py:73(factory)\n",
      "      498    0.013    0.000    0.013    0.000 {built-in method torch.tensor}\n",
      "     2194    0.002    0.000    0.013    0.000 /home/urkui-3/miniconda3/envs/env_isaaclab/lib/python3.10/site-packages/torch/_utils.py:773(_get_device_index)\n",
      "       32    0.000    0.000    0.013    0.000 /tmp/ipykernel_1891186/3689267830.py:16(make_env)\n",
      "       32    0.000    0.000    0.013    0.000 /home/urkui-3/miniconda3/envs/env_isaaclab/lib/python3.10/site-packages/gymnasium/envs/registration.py:646(make)\n",
      "     4388    0.002    0.000    0.012    0.000 /home/urkui-3/miniconda3/envs/env_isaaclab/lib/python3.10/site-packages/torch/cuda/__init__.py:116(is_available)\n",
      "      994    0.011    0.000    0.011    0.000 {built-in method torch._C._nn.linear}\n",
      "     2194    0.001    0.000    0.011    0.000 /home/urkui-3/miniconda3/envs/env_isaaclab/lib/python3.10/site-packages/torch/_utils.py:747(_get_current_device_index)\n",
      "     2194    0.001    0.000    0.010    0.000 /home/urkui-3/miniconda3/envs/env_isaaclab/lib/python3.10/site-packages/torch/_utils.py:733(_get_device_attr)\n",
      "       32    0.000    0.000    0.010    0.000 /home/urkui-3/miniconda3/envs/env_isaaclab/lib/python3.10/site-packages/gymnasium/envs/classic_control/cartpole.py:119(__init__)\n",
      "       32    0.000    0.000    0.009    0.000 /home/urkui-3/miniconda3/envs/env_isaaclab/lib/python3.10/site-packages/gymnasium/spaces/box.py:56(__init__)\n",
      "      497    0.000    0.000    0.009    0.000 /home/urkui-3/miniconda3/envs/env_isaaclab/lib/python3.10/site-packages/gymnasium/wrappers/common.py:112(step)\n",
      "      539    0.008    0.000    0.008    0.000 {method 'item' of 'torch._C.TensorBase' objects}\n",
      "      497    0.000    0.000    0.008    0.000 /home/urkui-3/miniconda3/envs/env_isaaclab/lib/python3.10/site-packages/gymnasium/wrappers/common.py:389(step)\n",
      "      497    0.000    0.000    0.008    0.000 /home/urkui-3/miniconda3/envs/env_isaaclab/lib/python3.10/site-packages/gymnasium/core.py:318(step)\n",
      "     4388    0.001    0.000    0.008    0.000 /home/urkui-3/miniconda3/envs/env_isaaclab/lib/python3.10/site-packages/torch/cuda/__init__.py:112(_nvml_based_avail)\n",
      "      497    0.000    0.000    0.008    0.000 /home/urkui-3/miniconda3/envs/env_isaaclab/lib/python3.10/site-packages/gymnasium/wrappers/common.py:277(step)\n",
      "     2194    0.007    0.000    0.007    0.000 {built-in method torch._C._cuda_synchronize}\n",
      "      497    0.004    0.000    0.007    0.000 /home/urkui-3/miniconda3/envs/env_isaaclab/lib/python3.10/site-packages/gymnasium/envs/classic_control/cartpole.py:164(step)\n",
      "       64    0.000    0.000    0.007    0.000 /home/urkui-3/miniconda3/envs/env_isaaclab/lib/python3.10/site-packages/gymnasium/spaces/box.py:14(array_short_repr)\n",
      "     4388    0.001    0.000    0.007    0.000 /home/urkui-3/miniconda3/envs/env_isaaclab/lib/python3.10/os.py:772(getenv)\n",
      "       64    0.000    0.000    0.006    0.000 /home/urkui-3/miniconda3/envs/env_isaaclab/lib/python3.10/site-packages/numpy/core/arrayprint.py:1595(_array_str_implementation)\n",
      "       64    0.000    0.000    0.006    0.000 /home/urkui-3/miniconda3/envs/env_isaaclab/lib/python3.10/site-packages/numpy/core/arrayprint.py:561(array2string)\n",
      "     2194    0.001    0.000    0.006    0.000 /home/urkui-3/miniconda3/envs/env_isaaclab/lib/python3.10/site-packages/torch/_utils.py:718(_get_available_device_type)\n",
      "       64    0.000    0.000    0.006    0.000 /home/urkui-3/miniconda3/envs/env_isaaclab/lib/python3.10/site-packages/numpy/core/arrayprint.py:506(wrapper)\n",
      "     4388    0.002    0.000    0.006    0.000 /home/urkui-3/miniconda3/envs/env_isaaclab/lib/python3.10/_collections_abc.py:821(get)\n",
      "       64    0.000    0.000    0.006    0.000 /home/urkui-3/miniconda3/envs/env_isaaclab/lib/python3.10/site-packages/numpy/core/arrayprint.py:523(_array2string)\n",
      "       32    0.000    0.000    0.005    0.000 /tmp/ipykernel_1891186/3689267830.py:78(<lambda>)\n",
      "     4388    0.002    0.000    0.004    0.000 /home/urkui-3/miniconda3/envs/env_isaaclab/lib/python3.10/os.py:675(__getitem__)\n",
      "      513    0.004    0.000    0.004    0.000 {built-in method torch.argmax}\n",
      "\n",
      "\n",
      "\n",
      "--- Custom timers (wall-clock, includes GPU sync where available) ---\n",
      "evaluate_population                 | total   0.1132s | calls    1 | avg   0.1132s\n",
      "forward                             | total   0.0292s | calls  497 | avg   0.0001s\n",
      "env.step                            | total   0.0154s | calls  497 | avg   0.0000s\n",
      "env.reset                           | total   0.0039s | calls   32 | avg   0.0001s\n",
      "set_flat_params                     | total   0.0036s | calls   32 | avg   0.0001s\n",
      "op:XPointCrossover.__call__         | total   0.0011s | calls    2 | avg   0.0006s\n",
      "op:TournamentSelection.__call__     | total   0.0005s | calls    1 | avg   0.0005s\n",
      "env.close                           | total   0.0005s | calls   32 | avg   0.0000s\n",
      "op:AdditiveMutation.__call__        | total   0.0002s | calls    1 | avg   0.0002s\n",
      "op:GlobalMutation.__call__          | total   0.0002s | calls    1 | avg   0.0002s\n",
      "op:RandomSelection.__call__         | total   0.0001s | calls    1 | avg   0.0001s\n",
      "-------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# profile_neuroevolution.py\n",
    "import time\n",
    "import cProfile\n",
    "import pstats\n",
    "import functools\n",
    "import importlib\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "\n",
    "# --- CONFIG -----------------------------------------------------------------\n",
    "# Path to your module (adjust import if you used a different module/name)\n",
    "# Create your env_maker as you normally would (example CartPole)\n",
    "try:\n",
    "    import gymnasium as gym  # optional\n",
    "    def make_env():\n",
    "        return gym.make(\"CartPole-v1\")\n",
    "except Exception:\n",
    "    # Fallback: the user should provide their own env_maker\n",
    "    raise RuntimeError(\"Please install gymnasium or adjust the env_maker in this script.\")\n",
    "\n",
    "POPULATION = 32\n",
    "GENERATIONS = 1\n",
    "EPISODES = 1\n",
    "\n",
    "# --- TIMER HELPERS ----------------------------------------------------------\n",
    "timers = defaultdict(lambda: {\"time\": 0.0, \"calls\": 0})\n",
    "\n",
    "def _sync_cuda():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "def time_wrapper(fn, name):\n",
    "    \"\"\"Return wrapped function that records time into timers[name].\"\"\"\n",
    "    @functools.wraps(fn)\n",
    "    def wrapped(*args, **kwargs):\n",
    "        _sync_cuda()\n",
    "        t0 = time.perf_counter()\n",
    "        try:\n",
    "            return fn(*args, **kwargs)\n",
    "        finally:\n",
    "            _sync_cuda()\n",
    "            t1 = time.perf_counter()\n",
    "            timers[name][\"time\"] += (t1 - t0)\n",
    "            timers[name][\"calls\"] += 1\n",
    "    return wrapped\n",
    "\n",
    "# --- MONKEYPATCH KEY METHODS -----------------------------------------------\n",
    "# Save originals so we can restore if needed\n",
    "_orig = {}\n",
    "\n",
    "# SimpleNet methods\n",
    "_orig['set_flat'] = SimpleNet.set_flat_params\n",
    "_orig['forward'] = SimpleNet.forward\n",
    "SimpleNet.set_flat_params = time_wrapper(SimpleNet.set_flat_params, \"set_flat_params\")\n",
    "SimpleNet.forward = time_wrapper(SimpleNet.forward, \"forward\")\n",
    "\n",
    "# Neuroevolution internals: evaluate loop + population ops\n",
    "_orig['evaluate'] = Neuroevolution._evaluate_population\n",
    "Neuroevolution._evaluate_population = time_wrapper(Neuroevolution._evaluate_population, \"evaluate_population\")\n",
    "\n",
    "# Operators (selection/mutation/crossover) -- wrap __call__ if subclass of Operator\n",
    "for cls in [XPointCrossover, AdditiveMutation, GlobalMutation,\n",
    "            TournamentSelection, BestSelection, RandomSelection, RouletteSelection]:\n",
    "    if hasattr(cls, \"__call__\"):\n",
    "        name = f\"op:{cls.__name__}.__call__\"\n",
    "        _orig[name] = cls.__call__\n",
    "        cls.__call__ = time_wrapper(cls.__call__, name)\n",
    "\n",
    "# Wrap env maker, env.reset, env.step and env.close by creating a thin proxy factory\n",
    "# We wrap the env_maker used by the evo instance below by providing a wrapper env_maker()\n",
    "def make_wrapped_env(orig_maker):\n",
    "    def factory():\n",
    "        env = orig_maker()\n",
    "        # wrap its methods if present\n",
    "        if hasattr(env, \"reset\"):\n",
    "            env_reset_orig = env.reset\n",
    "            env.reset = functools.wraps(env_reset_orig)(lambda *a, **kw: _wrap_env_method(env_reset_orig, \"env.reset\", *a, **kw))\n",
    "        if hasattr(env, \"step\"):\n",
    "            env_step_orig = env.step\n",
    "            env.step = functools.wraps(env_step_orig)(lambda *a, **kw: _wrap_env_method(env_step_orig, \"env.step\", *a, **kw))\n",
    "        if hasattr(env, \"close\"):\n",
    "            env_close_orig = env.close\n",
    "            env.close = functools.wraps(env_close_orig)(lambda *a, **kw: _wrap_env_method(env_close_orig, \"env.close\", *a, **kw))\n",
    "        return env\n",
    "    return factory\n",
    "\n",
    "def _wrap_env_method(fn, label, *a, **kw):\n",
    "    _sync_cuda()\n",
    "    t0 = time.perf_counter()\n",
    "    try:\n",
    "        return fn(*a, **kw)\n",
    "    finally:\n",
    "        _sync_cuda()\n",
    "        t1 = time.perf_counter()\n",
    "        timers[label][\"time\"] += (t1 - t0)\n",
    "        timers[label][\"calls\"] += 1\n",
    "\n",
    "# --- RUN PROFILE -------------------------------------------------------------\n",
    "def pretty_timers():\n",
    "    print(\"\\n--- Custom timers (wall-clock, includes GPU sync where available) ---\")\n",
    "    rows = []\n",
    "    for k, v in sorted(timers.items(), key=lambda kv: kv[1][\"time\"], reverse=True):\n",
    "        total = v[\"time\"]\n",
    "        calls = v[\"calls\"]\n",
    "        avg = total / calls if calls else 0.0\n",
    "        rows.append((k, total, calls, avg))\n",
    "    # print top 30\n",
    "    for k, total, calls, avg in rows[:50]:\n",
    "        print(f\"{k:35s} | total {total:8.4f}s | calls {calls:4d} | avg {avg:8.4f}s\")\n",
    "    print(\"-------------------------------------------------------------------\\n\")\n",
    "\n",
    "def main():\n",
    "    # Build evo with your chosen operators and net shape (small for quick profiling)\n",
    "    evo = Neuroevolution(\n",
    "        env_maker=make_wrapped_env(make_env),\n",
    "        population_size=POPULATION,\n",
    "        net_arch=(4, 32, 2),\n",
    "        operator_groups=[\n",
    "            (TournamentSelection(n=POPULATION//2, t=3), AdditiveMutation(0.02, 0.05), XPointCrossover(1, 0.9), POPULATION//2),\n",
    "            (RandomSelection(n=POPULATION//2), GlobalMutation(0.02, 0.5), XPointCrossover(2, 0.7), POPULATION//2),\n",
    "        ],\n",
    "        elite_fraction=0.05,\n",
    "    )\n",
    "\n",
    "    # Run a cProfile to get a general overview\n",
    "    pr = cProfile.Profile()\n",
    "    pr.enable()\n",
    "    evo.step(generations=GENERATIONS, episodes=EPISODES, verbose=True)\n",
    "    pr.disable()\n",
    "\n",
    "    # Print cProfile top results\n",
    "    print(\"\\n=== cProfile top 40 by cumulative time ===\")\n",
    "    ps = pstats.Stats(pr).sort_stats(\"cumtime\")\n",
    "    ps.print_stats(40)\n",
    "\n",
    "    # Print our custom timers (gives precise wall times for wrapped blocks)\n",
    "    pretty_timers()\n",
    "\n",
    "    # restore originals (optional)\n",
    "    SimpleNet.set_flat_params = _orig['set_flat']\n",
    "    SimpleNet.forward = _orig['forward']\n",
    "    Neuroevolution._evaluate_population = _orig['evaluate']\n",
    "    for cls in [XPointCrossover, AdditiveMutation, GlobalMutation,\n",
    "                TournamentSelection, BestSelection, RandomSelection, RouletteSelection]:\n",
    "        name = f\"op:{cls.__name__}.__call__\"\n",
    "        if name in _orig:\n",
    "            cls.__call__ = _orig[name]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_isaaclab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
